{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-X1jyzr2-0CU"
   },
   "source": [
    "## Lab 2. Text Normalization (cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7N56fAnP_Y5q"
   },
   "source": [
    "√én func»õie de task-ul pe care √Æl avem de realizat, putem alege una sau mai multe modalitƒÉ»õi de curƒÉ»õare a textului:\n",
    "- Transformarea textului √Æn litere mici\n",
    "- Eliminarea cifrelor »ôi numerelor (sau transformarea lor √Æn cuvinte)\n",
    "- Eliminarea link-urilor\n",
    "- Eliminarea emoticoanelor ( :) :D) »ôi a emoji-urilor (üíô üê±)\n",
    "- Eliminarea punctua»õiei\n",
    "- Eliminarea stopwords\n",
    "- Stemming/Lematizare\n",
    "- Tokenizare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB3R1dTTAxfH"
   },
   "source": [
    "Vom folosi setul de date `twitter_samples` din `nltk` (https://www.nltk.org/), care con»õine tweeturi pozitive »ôi negative. Vom folosi mai departe doar tweeturile pozitive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9IhXFIGB0DT",
    "outputId": "0d38ec86-dc1e-49c5-ec9e-d497b9d32776"
   },
   "outputs": [],
   "source": [
    "from sys import platform, path\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    path.append('/home/dariusbuhai/python/lib/python3.9/site-packages')\n",
    "import nltk\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf12x8hR-fJH",
    "outputId": "4a924129-ce1f-452b-e69a-98b184ec0acc"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus  import twitter_samples\n",
    "tweets = twitter_samples.strings('positive_tweets.json')\n",
    "tweets = tweets[500:520]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssjEnSunB6M-"
   },
   "source": [
    "### Transformarea textului √Æn litere mici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pb1BgZksCvof",
    "outputId": "1477de8c-73ce-47d0-d120-7d2dbddcea9e"
   },
   "outputs": [],
   "source": [
    "tweets_lower = [tweet.lower() for tweet in tweets]\n",
    "tweets_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7XWK416Cuv5"
   },
   "source": [
    "### Eliminarea cifrelor »ôi numerelor (sau transformarea lor √Æn cuvinte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDcI3R7fD-ys"
   },
   "source": [
    "Eliminarea cifrelor folosind regex `re`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u8TXNqflDN5O",
    "outputId": "21e60d89-8e95-49ab-bb6e-0b52345e7c4b"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "tweets_no_digits = [re.sub(r'\\d+', '', tweet) for tweet in tweets_lower]\n",
    "tweets_no_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvGx46VNEqfg"
   },
   "source": [
    "Convertirea cifrelor √Æn numere folosind `num2words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ls6HyuBnEOxP"
   },
   "outputs": [],
   "source": [
    "# ! pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDnBiJAHE1Y-",
    "outputId": "ba7d80e8-ff01-4c23-f4ef-cdf71ab9fe1b"
   },
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "\n",
    "tweets_num2words = []\n",
    "for tweet in tweets_lower:\n",
    "    tweets_num2words.append(' '.join([num2words(word) if word.isdigit() else word for word in tweet.split()]))\n",
    "\n",
    "tweets_num2words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wh-Y021CI2uJ"
   },
   "source": [
    "### Eliminarea link-urilor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inao55xqFz21",
    "outputId": "e51ac15c-2db2-4210-8f8c-4b6e06f63ee0"
   },
   "outputs": [],
   "source": [
    "tweets_no_links = [re.sub(r'http\\S+', '', tweet) for tweet in tweets_no_digits]\n",
    "tweets_no_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jh64SAwgJWWC"
   },
   "source": [
    "### Eliminarea emoticoanelor ( :) :D) »ôi a emoji-urilor (üíô üê±)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaviYAToJkYQ"
   },
   "source": [
    "Eliminarea emoticoanelor folosind regexul din [ nltk Twitter Tokenizer](https://github.com/nltk/nltk/blob/develop/nltk/tokenize/casual.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8_oVbzhJNnx",
    "outputId": "71e88e9a-c7d8-4e74-b050-b3538ac081f4"
   },
   "outputs": [],
   "source": [
    "emoticon_string = r\"\"\"\n",
    "    (?:\n",
    "      [<>]?\n",
    "      [:;=8]                     # eyes\n",
    "      [\\-o\\*\\']?                 # optional nose\n",
    "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
    "      |\n",
    "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
    "      [\\-o\\*\\']?                 # optional nose\n",
    "      [:;=8]                     # eyes\n",
    "      [<>]?\n",
    "      |\n",
    "      </?3                       # heart\n",
    "    )\"\"\"\n",
    "    \n",
    "emoticon_re = re.compile(emoticon_string, re.VERBOSE | re.I | re.UNICODE)\n",
    "tweets_no_emoticons = [re.sub(emoticon_re, '', tweet) for tweet in tweets_no_links]\n",
    "tweets_no_emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnBMWrqZKJqz"
   },
   "source": [
    "Eliminarea emoji-urilor folosind `emoji` [library](https://github.com/carpedm20/emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6t2BEfIKFSU"
   },
   "outputs": [],
   "source": [
    "# ! pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhnQ2Q4NKVs0"
   },
   "source": [
    "`get_emoji_regexp()` returneazƒÉ un regex care cuprinde toate emoji-urile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7uDKw1kKjyD",
    "outputId": "f54b74f3-f5fc-40e0-f53c-be17ea478425"
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "emoji_re = emoji.get_emoji_regexp()\n",
    "\n",
    "tweets_no_emoji = [re.sub(emoji_re,'', tweet) for tweet in tweets_no_emoticons]\n",
    "tweets_no_emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdin258uOTnl"
   },
   "source": [
    "### Eliminarea hashtag-urilor »ôi a men»õiunilor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFwfk66HOYid",
    "outputId": "6c2076e4-addd-4d82-cf10-b7deba18ef44"
   },
   "outputs": [],
   "source": [
    "tweets_no_hashtags = [re.sub(r'#[a-zA-Z0-9_]+','', tweet) for tweet in tweets_no_emoji]\n",
    "tweets_no_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zHnOHf2PSWQ",
    "outputId": "210fa440-f433-4b9d-8e67-9167653d47e4"
   },
   "outputs": [],
   "source": [
    "tweets_no_mentions = [re.sub(r'@[a-zA-Z0-9_]+','', tweet) for tweet in tweets_no_hashtags]\n",
    "tweets_no_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNCIM801Pd5s"
   },
   "source": [
    "EliminƒÉm spa»õiile multiple dintre cuvinte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rghP6xOoPlOv",
    "outputId": "806d14b4-aa04-4540-ec8d-456b1bbb207e"
   },
   "outputs": [],
   "source": [
    "tweets_no_spaces = [re.sub(r'\\s+', ' ', tweet).strip() for tweet in tweets_no_mentions]\n",
    "tweets_no_spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKUvVGcCP499"
   },
   "source": [
    "### Tokenizare\n",
    "\n",
    "- La nivel de propozi»õie: putem √ÆmpƒÉr»õi un text √Æn propozi»õii dupƒÉ punctua»õie, sau folosind [nltk.sent_tokenize](https://www.nltk.org/api/nltk.tokenize.html)\n",
    "\n",
    "- La nivel de cuv√¢nt: putem √ÆmpƒÉr»õi dupƒÉ spa»õiu, sau sƒÉ folosim [nltk.word_tokenize](https://www.nltk.org/api/nltk.tokenize.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BzS9XSCQn_Z"
   },
   "source": [
    "Tokenizare la nivel de popozi»õie folosind regex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aM7KEg-1RGxN",
    "outputId": "73bada5e-ea8a-456d-b5e2-87140da6c699"
   },
   "outputs": [],
   "source": [
    "twitter_sent_tokenized = [re.split('(?<=[.!?])\\s+', tweet) for tweet in tweets_no_spaces]\n",
    "twitter_sent_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "203iv3ESRblX"
   },
   "source": [
    "Folosind `nltk.sent_tokenize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UllfcSeRndQ"
   },
   "source": [
    "Mai √Ænt√¢i trebuie sƒÉ downloadƒÉm punctua»õia din `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4XsEbgFRt-S",
    "outputId": "2d76630c-76a3-4093-a2a2-b0ae036d5c3e"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2o6EMlSRfYZ",
    "outputId": "8a49f7d6-5ecc-4031-a9e3-ea3598f72f31"
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "twitter_sent_tokenized = [nltk.sent_tokenize(tweet) for tweet in tweets_no_spaces]\n",
    "twitter_sent_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNrcChKlSAuV"
   },
   "source": [
    "Tokenizare la nivel de cuv√¢nt dupƒÉ spa»õii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLJXmphYSFG0",
    "outputId": "3492d486-6faa-453c-f80b-343bd8864d7e"
   },
   "outputs": [],
   "source": [
    "for tweet_list in twitter_sent_tokenized:\n",
    "    print([tweet.split() for tweet in tweet_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niyRmQ86SyOg"
   },
   "source": [
    "Tokenizare la nivel de cuv√¢nt folosind `nltk.word_tokenize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nZasrqFVE-h",
    "outputId": "a042aefe-9a5e-4851-8474-f78947ef6ce3"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "twitter_word_tokenized = [word_tokenize(tweet) for tweet in tweets_no_spaces]\n",
    "twitter_word_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdT8MOurLMnj"
   },
   "source": [
    "### Eliminarea punctua»õiei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3PfeT7dNcxa"
   },
   "source": [
    "Folosind regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhhOuUZqK6ix",
    "outputId": "31000e5f-65bf-4e15-ca66-dfacf450ddf6"
   },
   "outputs": [],
   "source": [
    "tweets_no_punct = [re.sub(r'[^\\w\\s]', '', tweet) for tweet in tweets_no_spaces]\n",
    "tweets_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQfBOGzoNnLp"
   },
   "source": [
    "Folosind `string.punctuation()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MgdMyLm_Nl1D",
    "outputId": "ec244fee-0b52-4a3b-fdc0-644e800508e7"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnxNzTCBNyUS"
   },
   "source": [
    "Traducem fiecare semn de punctua»õie √Æn ' '."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oov3nDzoNulb",
    "outputId": "eedc98a5-b6b6-47e3-c9b0-facd7bf97f42"
   },
   "outputs": [],
   "source": [
    "tweets_no_punct = [tweet.translate(str.maketrans('', '', string.punctuation)) for tweet in tweets_no_spaces]\n",
    "tweets_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSoToGH2VEV7"
   },
   "source": [
    "Tokenizare la nivel de cuv√¢nt dupƒÉ eliminarea punctua»õiei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fQBkaVdVJVH",
    "outputId": "e51b64d8-dcd3-4435-8388-49e40da584f0"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "twitter_word_tokenized = [word_tokenize(tweet) for tweet in tweets_no_punct]\n",
    "twitter_word_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lye6YT5oWF-T"
   },
   "source": [
    "Aveti grija la cazurile de tipul \"unu,doi\". Daca eliminati punctuatia direct, cele doua cuvinte vor fi concatenate obtinand un singur cuvant \"unudoi\". O alternativa ar fi sa inlocuim mai intai toate caracterele de punctuatie cu spatiu, apoi sa aplicam inca o data metoda de contractie a spatiilor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJzIIFJZW2XO",
    "outputId": "ab79163b-f3b1-4445-ddbc-a1ebd5d62660"
   },
   "outputs": [],
   "source": [
    "tweets_no_punct = [re.sub(r'[^\\w\\s]', ' ', tweet) for tweet in tweets_no_spaces]\n",
    "tweets_no_punct = [re.sub(r'\\s+', ' ', tweet) for tweet in tweets_no_punct]\n",
    "tweets_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihBAuh1VUTlb"
   },
   "source": [
    "### Eliminarea stopwords\n",
    "\n",
    "![stopwords.jpg](https://user.oc-static.com/upload/2021/01/06/16099626487943_P1C2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq21UVgTSRQQ"
   },
   "source": [
    "Stopwords-urile sunt cele mai folosite cuvinte din limba engleza si au valoare sintactic morfologica, dar nu au si una semantica.\n",
    "Primele 4 stopwords-uri ale limbii engleze in ordinea aparitiei lor in limba: the, of, and, to.  \n",
    "Cele mai multe sunt pronume, prepozitii sau conjuctii. \n",
    "\n",
    "[The Zipf Law](https://www.youtube.com/watch?v=fCn8zs912OE) afirma ca daca notam $x$ = numarul de aparitii a lui \"the\", atunci numarul de aparitii al lui \"of\" va fi foarte apropiat de $\\frac{x}{2}$, al lui \"and\", de $\\frac{x}{3}$, al celui de-al n-lea cu $\\frac{x}{n}$ (distributia de probabilitati Pareto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9KsFEcKUhk2"
   },
   "source": [
    "Eliminare stopwords folosind `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0DX_U3ZUlI7",
    "outputId": "37e262f5-bd3e-4b8f-b46b-a14e9d4887dd"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPTyM23bOKOK",
    "outputId": "3b482654-a067-4062-8754-3edac5dde9e8"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words_nltk = set(stopwords.words('english'))\n",
    "print(len(stop_words_nltk))\n",
    "print(stop_words_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3xGtKBuUrW1",
    "outputId": "2f8526da-6b1c-4c42-85c3-d22973622817"
   },
   "outputs": [],
   "source": [
    "# flatten the lists\n",
    "all_words = [word for sent in twitter_word_tokenized for word in sent]\n",
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvidsxsBSfgp",
    "outputId": "0c740408-c819-4c5f-9598-99dc5751f21b"
   },
   "outputs": [],
   "source": [
    "all_words_without_stops = [word for word in all_words if word not in stop_words_nltk]\n",
    "all_words_without_stops[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omPFUw0jVhVd"
   },
   "source": [
    "Eliminare stopwords folosind `spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5_sNJXFXryH"
   },
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPHXLGa0Vkzz",
    "outputId": "73aac33f-91f9-4c2c-a961-ff2dae2d1edf"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words_spacy = nlp.Defaults.stop_words\n",
    "print(len(stop_words_spacy))\n",
    "print(stop_words_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osjomF35VqTd",
    "outputId": "d384155d-3ad9-4b5c-c3ce-03b3b57fae35"
   },
   "outputs": [],
   "source": [
    "all_words_without_stops = [word for word in all_words if word not in stop_words_spacy]\n",
    "all_words_without_stops[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Oenw_Uhxw31"
   },
   "source": [
    "Putem vizualiza distributia stopwords-urilor folosind matplolib sau wordcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDF2bRh6xxYv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "_tmNf1g3TWl_",
    "outputId": "6103a419-43b0-4684-eb82-78de0fc43d6d"
   },
   "outputs": [],
   "source": [
    "tweets_stopwords = [word for word in all_words if word in stop_words_spacy]\n",
    "values, frequencies = np.unique(tweets_stopwords, return_counts=True)\n",
    "stopwords_dict = {value: freq for value, freq in zip(values, frequencies)}\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.bar(values, frequencies, orientation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVd4-qbi0_fO"
   },
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "g39Nkrwm0Tbr",
    "outputId": "2224a1a8-2127-4a0e-ae47-3960485d4fb2"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=1000, background_color=\"white\")\n",
    "wordcloud_picture = wordcloud.generate_from_frequencies(stopwords_dict)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUbSWMrXVsFU"
   },
   "source": [
    "### Lematizare/Stemming\n",
    "\n",
    "Au rolul de a elimina inflexiunile cuvintelor: acele caractere care pot ingloba:\n",
    "- persoana unui verb, in romana: voi cauta**»õi** - persoana a2a plural\n",
    "- timpul unui verb, in romana: voi cauta**serƒÉ**»õi - mai mult ca perfectul\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IgxY-nAVvai"
   },
   "source": [
    "![1_HLQgkMt5-g5WO5VpNuTl_g.jpeg](https://miro.medium.com/max/564/1*HLQgkMt5-g5WO5VpNuTl_g.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zgx71FdXStx7"
   },
   "source": [
    "## Lematizarea\n",
    "Aduce cuvintele la forma lor din dictionar.\n",
    "\n",
    "\"Lemmatization is the process where we take individual tokens from a sentence and we try to reduce them to their base form. The process that makes this possible is having a vocabulary and performing morphological analysis to remove inflectional endings. The output of the lemmatization process (as shown in the figure above) is the lemma or the base form of the word. For instance, a lemmatization process reduces the inflections, \"am\", \"are\", and \"is\", to the base form, \"be\". Take a look at the figure above for a full example and try to understand what it's doing.\n",
    "\n",
    "Lemmatization is helpful for normalizing text for text classification tasks or search engines, and a variety of other NLP tasks such as sentiment classification. It is particularly important when dealing with complex languages like Arabic and Spanish.\" ([sursa](https://colab.research.google.com/github/dair-ai/notebooks/blob/master/_notebooks/2020-03-19-nlp_basics_tokenization_segmentation.ipynb#scrollTo=dcaLqxPX5CJa))\n",
    "\n",
    "## Pros:\n",
    "- rezultatele sunt cuvinte existente in limba\n",
    "\n",
    "## Cons\n",
    "- procesul de cautare poate fi costisitor dpdv. computational\n",
    "- limba este intr-o continua evolutie, iar de cele mai multe ori, dictionarele nu \"tin pasul\" cu toate cuvintele noi aparute sau imprumutate\n",
    "\n",
    "## Stemming\n",
    "Aplica algoiritmi ce folosesc automate finite (remember LFA). Multe dintre ele sunt scrise in limbajul [Snowball](http://snowball.tartarus.org/).\n",
    "\n",
    "\"Stemming is just a simpler version of lemmatization where we are interested in stripping the suffix at the end of the word. When stemming we are interesting in reducing the inflected or derived word to it's base form. Take a look at the figure above to get some intuition about the process.\n",
    "\n",
    "Both the stemming and the lemmatization processes involve morphological analysis where the stems and affixes (called the morphemes) are extracted and used to reduce inflections to their base form. For instance, the word cats has two morphemes, cat and s, the cat being the stem and the s being the affix representing plurality.\" ([sursa](https://colab.research.google.com/github/dair-ai/notebooks/blob/master/_notebooks/2020-03-19-nlp_basics_tokenization_segmentation.ipynb#scrollTo=dcaLqxPX5CJa))\n",
    "\n",
    "## Pros:\n",
    "- este mai rapida ca lematizarea\n",
    "- se adapteaza mai usor la cuvinte noi aparute in limba\n",
    "\n",
    "## Cons\n",
    "- rezultatele nu sunt intotdeauna, cuvinte existente in limba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp-zkrcdV2B9",
    "outputId": "f04fc56a-ca8e-4245-da4a-a4768ff9125d"
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Apples and oranges are similar boots and hippos aren't\")\n",
    "for word in doc:\n",
    "    print(word, '=>', word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzFUBINBSybR",
    "outputId": "fd66b136-0de2-4638-abf9-5f9ec8076ec9"
   },
   "outputs": [],
   "source": [
    "# spaCy doesn't support stemming so for this part we are going to use NLTK, which is another fantastic Python NLP library.\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "doc = 'I prefer not to argue'\n",
    "for token in doc.split(\" \"):\n",
    "    print(token, '=>' , stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNYz-8XPOlm7"
   },
   "source": [
    "Pentru procesarea datelor din social media putem folosi »ôi librƒÉrii dedicate, cum ar fi `Preprocessor`: https://github.com/s/preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRqdyJYsS4dZ"
   },
   "source": [
    "Collocations: in functie de context, putem analiza din toate n-gramele (de cuvinte sau caractere) cel mai probabile sa apara impreuna.\n",
    "\n",
    "Exemlu: bigrama - pereche de cuvinte cu sanse mari sa coexiste:\n",
    "('Jegar', 'Sahadutha'), ('Salt', 'Sea'), ('aromatic', 'resin').\n",
    "\n",
    "Putem aplica cateva functii din pachetul [collocations](https://www.nltk.org/howto/collocations.html) pe cuvintele gasite pe twitter, pentru a gasi top 15 bigrame folosind [Pointwise Mutual Information](https://en.wikipedia.org/wiki/Pointwise_mutual_information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZNzug2iS7tV",
    "outputId": "3e84ba2f-b5f4-42fd-b7a7-546e3c326e72"
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "colloc_founder = BigramCollocationFinder.from_words(all_words)\n",
    "\n",
    "bigram_results = colloc_founder.nbest(bigram_measures.pmi, 15)\n",
    "bigram_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2fNsFHSwAhU"
   },
   "source": [
    "## Unidecode \n",
    "Aduce caracterele utf8 la cea mai apropiata forma ASCII a lor. Este utila atat  pentru inlocuirea diacriticilor limbii romane, cat si pentru a gasi un echivalent pentru 'romanizarea' caracterele asiatice (desi obtine rezultate diferite de Hepburn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5BIgaTjvwwt",
    "outputId": "327adfdc-441f-4c56-d0a2-90fb700cbc08"
   },
   "outputs": [],
   "source": [
    "!pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "T4s4gTk5TdEm",
    "outputId": "a814a9de-eae5-4cc2-8eac-8d4452b2f582"
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "unidecode('Lene≈üul mai mult aleargƒÉ, scumpul mai mult pƒÉgube≈üte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EByAQYdDwZmc",
    "outputId": "3a816d0e-6dc1-49d8-bf8e-a3151f48649f"
   },
   "outputs": [],
   "source": [
    "unidecode('Âåó‰∫¨')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fESW_eHdTEL9"
   },
   "source": [
    "# TASK:\n",
    "\n",
    "###Deadline: 10 martie ora 23:59.\n",
    "###Formular pentru trimiterea temei: https://forms.gle/kMcWxv8e39wwXy1W7.\n",
    "\n",
    "\n",
    "Folosind datasetul urmator, https://github.com/ancatache/LaRoSeDa/tree/main/data - o colectie de review-uri pentru produse in romana, rezolvati urmatoarele cerinte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTPecjhoTEAJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Curatati si normalizati corpus-ul aplicand urmatoarele operatiii:\n",
    "\n",
    "    a) afisati caracterele diferite de literele mici ale alfabetului englez\n",
    "\n",
    "    b) transformati numerele in cuvinte folosind num2words   \n",
    "\n",
    "    c) eliminati linkurile si alte referinte\n",
    "\n",
    "    d) curatati-l de semnele de punctuatie\n",
    "\n",
    "    e) impartiti textele in cuvinte (tokens), va recomandam sa folositi `spacy` incarcand unul din modelele pentru limba romana (https://spacy.io/models/ro)\n",
    "\n",
    "    f) eliminati stopwords  \n",
    "\n",
    "    g) aplicati stemming  \n",
    "\n",
    "    h) aplicati lematizare peste cuvintele obtinute la punctul f. Comparand cu rezultatele de la punctul g, afisati top 15 cuvinte pentru care stemul este diferit de lema, sortate descrescator dupa numarul de caractere prin care stemul difera de lema.\n",
    "\n",
    "    i) cautati top 20 trigrame (collocations)\n",
    "\n",
    "\n",
    "2. Calculati frecventele de aparitie ale fiecarui token la punctul e) si punctul g). Plotati-le cum doriti, prin wordcloud sau plotbar. Ce diferente observati? (intrucat numarul de cuvinte distincte poate fi mare, puteti plota informatii doar despre cele mai frecvente N cuvinte)\n",
    "\n",
    "\n",
    "3. Plotati distributia numarului de tokens per review (nr. de reviews vs. nr. de tokens), atat pentru review-urile negative, cat si, separat, pentru cele pozitive. Ce observati?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}