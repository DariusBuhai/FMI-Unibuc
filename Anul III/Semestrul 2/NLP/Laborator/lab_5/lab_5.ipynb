{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FINAL_lab_5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# CNNs pentru clasificarea textelor\n","\n","Folosirea CNN-urilor pentru a clasifica textul a fost prima dată prezentată în: [Convolutional Neural Networks for Sentence Classification](https://aclanthology.org/D14-1181.pdf).\n","\n","### Arhitectura CNN\n","\n","<img src=\"https://richliao.github.io/images/YoonKim_ConvtextClassifier.png\">\n","\n","Dându-se ca input un text de $n$ cuvinte $w_{1}$, $w_{2}$, ..., $w_{n}$, transformăm fiecare cuvânt într-un vector de dimensiune $d$, rezultând vectorii $w_{1}$, $w_{2}$, ..., $w_{n}$ aparținând $R^d$. Matricea rezultată de dimensiune $d$×$n$ este apoi folosită ca input pentru un layer convoluțional care trece un *sliding window* peste text.\n","\n","Pentru fiecare window de lungime $l$:\n","\n","$u_{i}$ = [$w_{i}$, ..., $w_{i+l-1}$] $∈ R^{d×l}$, 0≤$i$≤$n-l$ \n","\n","Pentru fiecare filtru $f_{j} ∈ R^{d×l}$ calculăm <$u_{i}$, $f_{j}$> și obținem matricea $ F ∈ R^{m×n}$ (dacă am făcut padding înainte de aplicarea filtrului, astfel încât să păstrăm dimensiunea $n$ a cuvintelor), unde $m$ este numărul de filtre. Aplicăm max-pooling pe matricea $F$ rezultată, apoi aplicăm funcția de activare. În final, avem un layer *fully connected* care produce distribuția pe clase, din care rezultă clasa cu cea mai mare probabilitate."],"metadata":{"id":"YNzBsYHukEf-"}},{"cell_type":"markdown","source":["### Convoluții și filtre\n","\n","<img src=\"https://debajyotidatta.github.io/assets/images/conv.001.png\" width=\"300\">\n","\n","**Inputul** este format dintr-o matrice de dimensiune $n$×$d$, unde $n$ este numărul de cuvinte sau caractere, iar $d$ este lungimea reprezentării vectoriale sau lungimea vocabularului.  \n","\n","De exemplu, pentru reprezentarea vectorială a unui text la nivel de caracter, pentru $d$ = 70, numărul de caractere unice în vocabular, pe fiecare linie a matricei avem reprezentarea one-hot a unui caracter.\n","\n","<img src=\"https://debajyotidatta.github.io/assets/images/conv.002.png\" width=\"500\">\n","\n","**Filtrele** (kernels) pot avea orice lungime. Lungimea este dată de numărul de linii din filtru. Lățimea filtrului trebuie să fie aceeași cu numărul de coloane din reprezentarea vectorială ($d$).\n","\n","<img src=\"https://debajyotidatta.github.io/assets/images/conv.003.png\" width=\"300\">\n","\n","Operația de convoluție presupune multiplicarea elementelor din input și filtru, rezultând o valoare care reprezintă suma rezultatelor multiplicării. În consecință, operația de convoluție multiplică *weight*-urile din filtru cu reprezentarea vectorială a cuvintelor.\n","\n","<img src=\"https://debajyotidatta.github.io/assets/images/conv.004.png\" width=\"300\">\n","\n","<img src=\"https://debajyotidatta.github.io/assets/images/conv.005.png\" width=\"300\">\n","\n","<img src=\"https://debajyotidatta.github.io/assets/images/conv.006.png\" width=\"300\">\n","\n","Filtrul este aplicat secvențial peste input, dar, la fel ca în cazul imaginilor, putem folosi diferite valori pentru *stride* pentru a controla cât de mult de mișcă filtrul vertical. Utilizând *stride* cu o valoare $k$ putem aplica un filtrul din $k$ în $k$ linii. De exemplu, pentru un filtru cu stride = 2, filtrul va fi aplicat pe secvența de text din 2 în 2 linii și vom avea un output de dimensiune mai mică.\n","\n","<img src=\"https://debajyotidatta.github.io/assets/images/conv2.006.png\" width=\"450\">\n","\n","Filtre multiple vor produce output-uri multiple. \n","\n","<img src=\"https://debajyotidatta.github.io/assets/images/conv2.007.png\" width=\"450\">\n","\n","La următorul pas se realizează *max pooling* peste fiecare feature map rezultat din aplicarea filtrelor, iar apoi rezultatele sunt concatenate. \n","\n"],"metadata":{"id":"Rn2QNjUCg6z0"}},{"cell_type":"markdown","source":["### Imagini vs Text\n","\n","Pentru a înțelege de ce o abordare folosind CNN-uri este potrivită pentru text, trebuie să ne gândim la textele noastre ca fiind niște imagini.\n","\n","Pentru exemplul următor vom cosidera că reprezentarea unei propoziții a fost făcută la nivel de cuvânt.\n","\n","De exemplu, pentru o propoziție cu lungimea maximă de 70 de cuvinte și lungimea embeddingului egală cu 300, putem crea o matrice cu valori numerice de forma 70x300 pentru a reprezenta această propoziție. Spre deosebire de imagini, în care elementele matricei sunt reprezentate de valori ale pixelilor, fiecare linie din reprezentarea vectorială a propoziției este, de fapt, reprezentarea unui cuvânt.\n","\n","În cazul imaginilor, filtrul de convoluție se deplasează și vertical și orizontal, dar în cazul textului, filtrul se deplasează doar vertical, convoluțiile sunt doar 1D. Un kernel de dimensiune (2, 300), care are dimensiunea filtrului egală cu 2 se uită doar la 2 cuvinte în același timp. Ne putem gândi, deci, la dimensionea filtrelor ca la o dimensiune a n-gramelor (bigrame, trigrame, etc.)."],"metadata":{"id":"T3_PYPN8fajE"}},{"cell_type":"markdown","source":["În acest laborator vom folosi datasetul IMDb movie reviews: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"],"metadata":{"id":"4Z5b8qtPXLdB"}},{"cell_type":"code","source":["! pip install unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSKhMG6_U9Ch","outputId":"f107aac1-8bd5-4c2d-bd77-7a46b2c04fc1","executionInfo":{"status":"ok","timestamp":1647392850585,"user_tz":-120,"elapsed":7357,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.4)\n"]}]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","from pprint import pprint\n","from sklearn.model_selection import train_test_split\n","from unidecode import unidecode\n","from collections import Counter\n","import nltk\n","from nltk import word_tokenize\n","nltk.download('punkt')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3RBIBZPU2Qp","outputId":"e116e69b-7df3-4d09-814f-3fc6f1807c8b","executionInfo":{"status":"ok","timestamp":1647392850586,"user_tz":-120,"elapsed":20,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["from urllib.request import urlretrieve\n","urlretrieve('https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv', 'IMDB_Dataset.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDEgcB_E8uWL","outputId":"85a8b8ad-a943-4cdd-c823-2a159107558d","executionInfo":{"status":"ok","timestamp":1647392851637,"user_tz":-120,"elapsed":1059,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('IMDB_Dataset.csv', <http.client.HTTPMessage at 0x7f33d2e30610>)"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","execution_count":73,"metadata":{"id":"Q1cush6tEdAk","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"3c6cdf01-a5fe-4c7d-9afb-fab40006d5f5","executionInfo":{"status":"ok","timestamp":1647392852435,"user_tz":-120,"elapsed":802,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 review  sentiment\n","0     My family and I normally do not watch local mo...          1\n","1     Believe it or not, this was at one time the wo...          0\n","2     After some internet surfing, I found the \"Home...          0\n","3     One of the most unheralded great works of anim...          1\n","4     It was the Sixties, and anyone with long hair ...          0\n","...                                                 ...        ...\n","9995  The film maybe goes a little far, but if you l...          1\n","9996  This two-parter was excellent - the best since...          1\n","9997  Shaggy & Scooby-Doo Get a Clue. It's like watc...          0\n","9998  Todd Rohal is a mad genius. \"Knuckleface Jones...          1\n","9999  Charlie Wilson's War, based on a true story, t...          1\n","\n","[10000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-31490719-0a88-44b9-952f-4c5370c77649\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>My family and I normally do not watch local mo...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Believe it or not, this was at one time the wo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>After some internet surfing, I found the \"Home...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>One of the most unheralded great works of anim...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>It was the Sixties, and anyone with long hair ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>The film maybe goes a little far, but if you l...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>This two-parter was excellent - the best since...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>Shaggy &amp; Scooby-Doo Get a Clue. It's like watc...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>Todd Rohal is a mad genius. \"Knuckleface Jones...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>Charlie Wilson's War, based on a true story, t...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31490719-0a88-44b9-952f-4c5370c77649')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-31490719-0a88-44b9-952f-4c5370c77649 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-31490719-0a88-44b9-952f-4c5370c77649');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":73}],"source":["data = pd.read_csv('IMDB_Dataset.csv')\n","data = data[:10000]\n","data"]},{"cell_type":"markdown","source":["Impartim datasetul in train si test."],"metadata":{"id":"qaZmejBvY2jK"}},{"cell_type":"code","source":["train_df, test_df = train_test_split(data, test_size=0.20, random_state = 42)\n","\n","print('Dimensiunea datelor de train', len(train_df))\n","print('Dimensiunea datelor de test', len(test_df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVFj4JHVY19U","outputId":"a7d98a81-593e-415a-c363-3a9851e55ce8","executionInfo":{"status":"ok","timestamp":1647392852435,"user_tz":-120,"elapsed":12,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimensiunea datelor de train 8000\n","Dimensiunea datelor de test 2000\n"]}]},{"cell_type":"markdown","source":["Așa cum am văzut în laboratoarele trecute, nu putem antrena un model direct pe datele sub formă de text, trebuie să transformam datele în reprezentări numerice vectoriale. \n","\n","Pentru asta, trebuie să parcurgem 2 pași:\n","\n","- **Tokenizare**: împărțirea textelor în subtexte mai mici. Astfel vom determina vocabularul setului nostru de date (setul de tokeni unici)\n","\n","- **Vectorizare**: reprezentarea în format numeric vectorial"],"metadata":{"id":"4i3KQ4qbkcR3"}},{"cell_type":"markdown","source":["Textul poate fi reprezentat fie ca o secvență de caractere, fie ca o secvență de cuvinte. Utilizarea reprezentării la nivel de cuvânt are o performanță mai bună și este mai folosită, pe când reprezentarea la nivel de caracter este utilă dacă textele au multe greșeli de scriere. "],"metadata":{"id":"UfqLJKKSlGZ9"}},{"cell_type":"markdown","source":["### Reprezentarea vectorială la nivel de caracter"],"metadata":{"id":"5VNrOeWin9YU"}},{"cell_type":"markdown","source":["\n","```\n","Texts: 'the mouse ran up the clock' and 'the mouse ran down'\n","```\n","\n","Pe langa caracterele prezente in textele noastre, adaugam si 2 tokeni speciali: UNK (unknown) si PAD.\n","\n","\n","```\n","Index assigned for every token: {0: 'UNK', 1: 'PAD', 2: 't', 3: 'm', 4: 'c', 5: 'h', 6: 'l', 7: 'w', 8: ' ', 9: 'a', 10: 'k', 11: 'e', 12: 'r', 13: 'u', 14: 'n', 15: 's', 16: 'd', 17: 'p', 18: 'o'}\n","```\n","\n","Reprezentarea vectoriala a celor doua texte folosind indexul corespunzator pentru fiecare caracter:\n","\n","```\n","'the mouse ran up the clock' = [2, 5, 11, 8, 3, 18, 13, 15, 11, 8, 12, 9, 14, 8, 13, 17, 8, 2, 5, 11, 8, 4, 6, 18, 4, 10]\n","'the mouse ran down' = [2, 5, 11, 8, 3, 18, 13, 15, 11, 8, 12, 9, 14, 8, 16, 18, 7, 14]\n","```\n","\n","Adaugam valori de padding la cel de-al doilea vector pentru a avea o lungime egala cu primul vector si obtinem:\n","\n","```\n","[2, 5, 11, 8, 3, 18, 13, 15, 11, 8, 12, 9, 14, 8, 16, 18, 7, 14, 1, 1, 1, 1, 1, 1, 1, 1]\n","```"],"metadata":{"id":"fmzl7MpVECgF"}},{"cell_type":"markdown","source":["Transformăm lista de review-uri într-o listă de caractere pentru fiecare review."],"metadata":{"id":"EUVIwpq-q1b-"}},{"cell_type":"code","source":["def transform_to_char(data):\n","\n","    reviews = []\n","    \n","    for review in data:\n","        review_cleaned = [char.lower() for char in review]\n","        reviews.append(review_cleaned)\n","\n","    return reviews\n","\n","train_reviews = transform_to_char(train_df.review)\n","train_labels = train_df.sentiment.tolist()\n","\n","print('Reviews', len(train_reviews))\n","print('Labels', len(train_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3FfaGAeoKBW","outputId":"886715e1-108d-46f8-de6b-f26ead83e328","executionInfo":{"status":"ok","timestamp":1647392854167,"user_tz":-120,"elapsed":1740,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Reviews 8000\n","Labels 8000\n"]}]},{"cell_type":"markdown","source":["Calculam marimea vocabularului de caractere."],"metadata":{"id":"z9FozeZ1uyeL"}},{"cell_type":"code","source":["def get_vocab(data):\n","\n","    units = set([unit for review in data for unit in review])\n","    \n","    return units\n","\n","vocab = get_vocab(train_reviews)\n","\n","print('total chars:', len(vocab))\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjMZZNaEojSq","outputId":"aa944ba3-6cdc-4893-868b-d1bbdee036f1","executionInfo":{"status":"ok","timestamp":1647392856234,"user_tz":-120,"elapsed":2073,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["total chars: 128\n","{'m', '0', '%', 'è', \"'\", 'ú', 'p', 'l', 'ô', '6', 'æ', '\\x84', 'ג', 'מ', '”', '}', '³', '{', 'r', '>', '@', '\\x85', '~', 'ê', 'b', 'י', ')', '-', 'á', '\\x96', 'í', ';', 'y', '^', '*', '[', '\\x91', 'ä', 'h', '¨', 'w', ',', '`', '‘', '#', '\\x80', 'ן', '\\\\', '=', 'ó', 'ã', '8', 'ë', 'q', '1', '“', '<', '5', 'é', 'õ', 'k', 'x', '£', 'a', 'j', 'ø', 't', '.', '&', 'â', ':', 'î', 'ל', '¢', 'ר', '«', 's', '\\x97', '–', '´', '’', 'å', '!', '9', 'u', ' ', 'f', '+', 'n', 'א', '®', '3', 'ו', '\\t', '½', 'à', '$', '\\xa0', '7', 'ð', 'z', '2', 'e', '\\x95', '4', '|', 'd', 'v', '?', '\"', 'כ', 'ç', 'i', 'ï', 'ñ', 'ý', 'ü', '/', ']', 'ß', 'g', 'ö', '…', 'o', 'c', '»', '_', '('}\n"]}]},{"cell_type":"markdown","source":["Putem vedea ca avem foarte multe caractere cu accente, diferite de caracterele limbii engleze. Pentru a micsora lungimea vocabularului, putem transforma caracterele utf8 in cea mai apropiata forma ASCII a lor."],"metadata":{"id":"yFpdaZWW3JSj"}},{"cell_type":"code","source":["reviews_to_ascii = [unidecode(review) for review in train_df.review]\n","train_reviews = transform_to_char(reviews_to_ascii)\n","vocab = get_vocab(train_reviews)\n","\n","print('total chars:', len(vocab))\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Mz0gE3uWNV0","outputId":"3c0dac72-5fa8-4b2a-8fae-caeaf0fb0ab0","executionInfo":{"status":"ok","timestamp":1647392860877,"user_tz":-120,"elapsed":4649,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["total chars: 70\n","{'m', '[', 'x', '0', '%', 'a', 'j', '$', 'h', \"'\", 't', 'p', '.', 'l', '&', '6', '7', 'w', 'z', ',', '}', ':', '{', '2', 'e', 'r', '>', '`', '4', '@', 's', '^', '#', '|', 'd', 'v', '~', '\\\\', '?', '\"', '=', 'b', 'i', '!', '9', '8', 'q', 'u', ')', '/', ' ', 'g', 'f', '-', '<', 'o', '1', 'c', '+', ']', 'n', ';', '5', 'y', '_', '3', 'k', '(', '*', '\\t'}\n"]}]},{"cell_type":"markdown","source":["Atribuim fiecarui caracter din vocabularul nostru un index. Vom atribui 0 caracterelor necunoscute, iar 1 va fi valoarea atribuita paddingului."],"metadata":{"id":"745uYasFu4Eq"}},{"cell_type":"code","source":["char_indices = dict((c, i + 2) for i, c in enumerate(vocab))\n","indices_char = dict((i + 2, c) for i, c in enumerate(vocab))\n","\n","indices_char[0] = 'UNK'\n","char_indices['UNK'] = 0\n","\n","indices_char[1] = 'PAD'\n","char_indices['PAD'] = 1\n","\n","print('Dimensiunea vocabularului', len(indices_char))\n","print(indices_char)"],"metadata":{"id":"ntu0UPDNrtHh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"73113fca-b854-4e67-8a8a-2fdd879cce9e","executionInfo":{"status":"ok","timestamp":1647392860880,"user_tz":-120,"elapsed":21,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimensiunea vocabularului 72\n","{2: 'm', 3: '[', 4: 'x', 5: '0', 6: '%', 7: 'a', 8: 'j', 9: '$', 10: 'h', 11: \"'\", 12: 't', 13: 'p', 14: '.', 15: 'l', 16: '&', 17: '6', 18: '7', 19: 'w', 20: 'z', 21: ',', 22: '}', 23: ':', 24: '{', 25: '2', 26: 'e', 27: 'r', 28: '>', 29: '`', 30: '4', 31: '@', 32: 's', 33: '^', 34: '#', 35: '|', 36: 'd', 37: 'v', 38: '~', 39: '\\\\', 40: '?', 41: '\"', 42: '=', 43: 'b', 44: 'i', 45: '!', 46: '9', 47: '8', 48: 'q', 49: 'u', 50: ')', 51: '/', 52: ' ', 53: 'g', 54: 'f', 55: '-', 56: '<', 57: 'o', 58: '1', 59: 'c', 60: '+', 61: ']', 62: 'n', 63: ';', 64: '5', 65: 'y', 66: '_', 67: '3', 68: 'k', 69: '(', 70: '*', 71: '\\t', 0: 'UNK', 1: 'PAD'}\n"]}]},{"cell_type":"markdown","source":["Acum putem transforma propozitiile din datasetul nostru intr-o reprezentare vectoriala, in care vom avea pentru fiecare caracter indicele corespunzator din vocabularul nostru."],"metadata":{"id":"pXmYEKsUYHNf"}},{"cell_type":"code","source":["import numpy as np\n","\n","def vectorize_sentences(data, char_indices, one_hot = False):\n","    vectorized = []\n","    for sentences in data:\n","\n","        # transformam fiecare review in reprezentarea lui sub forma de indici ale caracterelor continute\n","        sentences_of_indices = [char_indices[w] if w in char_indices.keys() else char_indices['UNK'] for w in sentences]\n","\n","        # pentru fiecare indice putem face reprezentarea one-hot corespunzatoare\n","        # sau putem sa nu facem asta si sa adaugam un embedding layer in model care face această transformare\n","        if one_hot:\n","            sentences_of_indices = np.eye(len(char_indices))[sentences_of_indices]\n","\n","        vectorized.append(sentences_of_indices)\n","\n","    return vectorized\n","\n","train_reviews_vectorized = vectorize_sentences(train_reviews, char_indices)\n","# train_reviews_vectorized[0]"],"metadata":{"id":"D7Xjjjgfsw8S","executionInfo":{"status":"ok","timestamp":1647392866264,"user_tz":-120,"elapsed":5397,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["vectors_dim = [len(repr) for repr in train_reviews_vectorized]\n","vectors_dim[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVwubTwmgIqH","outputId":"d8c2ddbb-61c7-4f85-882f-250bba6cd19d","executionInfo":{"status":"ok","timestamp":1647392866265,"user_tz":-120,"elapsed":15,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1957, 370, 903, 3001, 1403]"]},"metadata":{},"execution_count":80}]},{"cell_type":"markdown","source":["Putem vedea ca deoarece review-urile au numar diferit de caractere, in consecinta, si dimensiunile reprezentarilor vectoriale sunt diferite. \n","Vom aduce reprezentarile noastre la aceeasi dimensiune maxima.\n","\n","Definim o functie *pad* care:\n","\n","- primeste un set de review-uri si o lungime maxima\n","- scurteaza toate reprezentarile mai mari decat lungimea maxima\n","- adauga valoarea de padding (1 in cazul nostru) la reprezentarile mai scurte decat lungimea maxima"],"metadata":{"id":"m2z30TbuiFH8"}},{"cell_type":"code","source":["def pad(samples, max_length):\n","    \n","    return torch.tensor([\n","        sample[:max_length] + [1] * max(0, max_length - len(sample))\n","        for sample in samples\n","    ])"],"metadata":{"id":"R1NeqnXkXh0A","executionInfo":{"status":"ok","timestamp":1647392866268,"user_tz":-120,"elapsed":13,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["train_reviews_vectorized = pad(train_reviews_vectorized, max_length = 1000)\n","train_reviews_vectorized"],"metadata":{"id":"-xkuZPbUXJBR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a1e495a-0782-4e7d-8eea-ff28e325f688","executionInfo":{"status":"ok","timestamp":1647392867963,"user_tz":-120,"elapsed":1706,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[44, 12, 52,  ..., 49, 32, 12],\n","        [36, 44, 36,  ...,  1,  1,  1],\n","        [12, 10, 44,  ...,  1,  1,  1],\n","        ...,\n","        [44, 52, 15,  ...,  1,  1,  1],\n","        [36, 26, 32,  ...,  1,  1,  1],\n","        [12, 10, 44,  ...,  1,  1,  1]])"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["train_reviews_vectorized.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wonME0qbHOdJ","outputId":"3b4cb0aa-be92-4718-8494-c61aa6522f3d","executionInfo":{"status":"ok","timestamp":1647392867964,"user_tz":-120,"elapsed":11,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8000, 1000])"]},"metadata":{},"execution_count":83}]},{"cell_type":"markdown","source":["Tranformăm și review-urile din setul de test într-o reprezentare vectorială"],"metadata":{"id":"T4UI32abSffV"}},{"cell_type":"code","source":["test_reviews_to_ascii = [unidecode(review) for review in test_df.review]\n","test_reviews = transform_to_char(test_reviews_to_ascii)\n","test_labels = test_df.sentiment.tolist()\n","\n","print('Reviews', len(test_reviews))\n","print('Labels', len(test_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CKT9Fq7wSjKY","outputId":"295f9c77-fb31-4478-ede4-2f4b19ef0c15","executionInfo":{"status":"ok","timestamp":1647392869753,"user_tz":-120,"elapsed":1794,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Reviews 2000\n","Labels 2000\n"]}]},{"cell_type":"code","source":["test_reviews_vectorized = vectorize_sentences(test_reviews, char_indices)\n","test_reviews_vectorized = pad(test_reviews_vectorized, max_length = 1000)\n","# test_reviews_vectorized[0]"],"metadata":{"id":"LvFzxZKYS8W0","executionInfo":{"status":"ok","timestamp":1647392871690,"user_tz":-120,"elapsed":1942,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":["Vom incarca seturile noastre de date intr-un obiect din clasa [Dataset](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset)."],"metadata":{"id":"nvD0iwNrH9Tu"}},{"cell_type":"code","source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, samples, labels):\n","        self.samples = samples\n","        self.labels = labels\n","            \n","    def __getitem__(self, k):\n","        \"\"\"Returneaza al k-lea exemplu din dataset\"\"\"\n","        return self.samples[k], self.labels[k]\n","    \n","    def __len__(self):\n","        \"\"\"Returneaza dimensiunea datasetului\"\"\"\n","        return len(self.samples)"],"metadata":{"id":"tC2sg5M3H8mT","executionInfo":{"status":"ok","timestamp":1647392871692,"user_tz":-120,"elapsed":16,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":["Definim arhitectura modelului"],"metadata":{"id":"jB3HhhKKIeDW"}},{"cell_type":"code","source":["class Model(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        # Definim un embedding layer cu un vocabular de dimensiune 72\n","        # și ca output un embedding de dimensiune 20\n","        # padding_idx este indexul din vocabular al paddingului (1, în cazul nostru)\n","        \n","        self.embedding = torch.nn.Embedding(72, 20, padding_idx=1)\n","\n","        # Definim o secvență de layere\n","        \n","        # Un layer Convolutional 1D cu 20 input channels, 32 output channels, dimensiune kernel = 3 și padding = 1\n","        # ReLU activation\n","        # 1D Maxpooling layer de dimensiune 2\n","        conv1 = torch.nn.Sequential(\n","            torch.nn.Conv1d(in_channels=20, out_channels=32, kernel_size=3, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool1d(kernel_size=2),\n","        )\n","        \n","        # Un layer Convolutional 1D cu 32 input channels, 32 output channels, dimensiune kernel = 5 și padding = 2\n","        # ReLU activation\n","        # 1D Maxpooling layer de dimensiune 2\n","        conv2 = torch.nn.Sequential(\n","            torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5, padding=2),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool1d(kernel_size=2),\n","        )\n","        \n","        # Global Average pooling layer care, în cazul nostru, este un 1D Avgerage Pooling layer\n","        # cu dimensiunea de 250 și stride 250\n","        global_average = torch.nn.AvgPool1d(kernel_size=250, stride=250)\n","\n","        self.convolutions = torch.nn.Sequential(\n","            conv1, conv2, global_average\n","        )\n","        \n","        # Flattening layer\n","        flatten = torch.nn.Flatten()\n","        \n","        # Linear layer cu 32 input features și 2 outputs fără funcție de activare\n","        linear = torch.nn.Linear(in_features=32, out_features=2)\n","\n","        self.classifier = torch.nn.Sequential(flatten, linear)\n","        \n","    def forward(self, input):\n","        # trecem inputul prin layerul de embedding\n","        embeddings = self.embedding(input)\n","        \n","        # permutăm inputul astfel încât prima dimensiune este numărul de channels\n","        embeddings = embeddings.permute(0, 2, 1)\n","        \n","        # trecem inputul prin secvența de layere\n","        output = self.convolutions(embeddings)\n","        output = self.classifier(output)\n","        return output\n"],"metadata":{"id":"SHQYbpUhQZXs","executionInfo":{"status":"ok","timestamp":1647392871694,"user_tz":-120,"elapsed":16,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["DEVICE = torch.device(\"cuda\")\n","# instanțiem modelul\n","model = Model().to(DEVICE)\n","\n","# Adam optimizer cu lr = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Cross Entropy loss\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# training dataset and dataloader\n","# test dataset and dataloader\n","train_ds = Dataset(train_reviews_vectorized, train_labels)\n","train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n","test_ds = Dataset(test_reviews_vectorized, test_labels)\n","test_dl = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=False)"],"metadata":{"id":"miX4Qat9SBTK","executionInfo":{"status":"ok","timestamp":1647392871695,"user_tz":-120,"elapsed":15,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":["Training loop"],"metadata":{"id":"bVy9KScOVgCa"}},{"cell_type":"code","source":["best_val_acc = 0\n","for epoch_n in range(10):\n","    print(f\"Epoch #{epoch_n + 1}\")\n","    model.train()\n","    for batch in train_dl:\n","        model.zero_grad()\n","\n","        inputs, targets = batch\n","        inputs = inputs.long().to(DEVICE)\n","        targets = targets.to(DEVICE)\n","\n","        output = model(inputs)\n","        loss = loss_fn(output, targets)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # validare\n","    model.eval()\n","    all_predictions = torch.tensor([])\n","    all_targets = torch.tensor([])\n","    for batch in test_dl:\n","        inputs, targets = batch\n","        inputs = inputs.long().to(DEVICE)\n","        targets = targets.to(DEVICE)\n","\n","        with torch.no_grad():\n","            output = model(inputs)\n","\n","        predictions = output.argmax(1)\n","        all_targets = torch.cat([all_targets, targets.detach().cpu()])\n","        all_predictions = torch.cat([all_predictions, predictions.detach().cpu()])\n","\n","    val_acc = (all_predictions == all_targets).float().mean().numpy()\n","    print(val_acc)\n","\n","    if val_acc > best_val_acc:\n","        torch.save(model.state_dict(), \"./model\")\n","        best_val_acc = val_acc\n","\n","print(\"Best validation accuracy\", best_val_acc)"],"metadata":{"id":"8jQzscISIdYG","executionInfo":{"status":"ok","timestamp":1647392887227,"user_tz":-120,"elapsed":15544,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"07a0585e-963c-48fd-86ab-25030e04cd6d"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch #1\n","0.5185\n","Epoch #2\n","0.527\n","Epoch #3\n","0.623\n","Epoch #4\n","0.637\n","Epoch #5\n","0.625\n","Epoch #6\n","0.6095\n","Epoch #7\n","0.6675\n","Epoch #8\n","0.658\n","Epoch #9\n","0.657\n","Epoch #10\n","0.6855\n","Best validation accuracy 0.6855\n"]}]},{"cell_type":"markdown","source":["### Reprezentarea vectoriala la nivel de cuvant\n"],"metadata":{"id":"XdrDykrMHAwF"}},{"cell_type":"markdown","source":["\n","```\n","Texts: 'The mouse ran up the clock' and 'The mouse ran down'\n","```\n","\n","Pe langa tokenii prezenti in textele noastre, adaugam si 2 tokeni speciali: UNK (unknown word) si PAD.\n","\n","\n","```\n","Index assigned for every token: {'UNK': 0, 'PAD': 1, 'the': 2, 'mouse': 3, 'ran': 4, 'up': 5, 'clock': 6, 'down': 7}\n","```\n","\n","Reprezentarea vectoriala a celor doua texte folosind indexul corespunzator pentru fiecare cuvant:\n","\n","```\n","'The mouse ran up the clock' = [2, 3, 4, 5, 2, 6]\n","'The mouse ran down' = [2, 3, 4, 7]\n","```\n","\n","Adaugam valori de padding la cel de-al doilea vector pentru a avea o lungime egala cu primul vector si obtinem:\n","\n","```\n","[2, 3, 4, 7, 1, 1]\n","```\n","Reprezentarea one-hot a fiecarui text:\n","\n","```\n","'The mouse ran up the clock' = [[0. 0. 1. 0. 0. 0. 0.]\n","                                [0. 0. 0. 1. 0. 0. 0.]\n","                                [0. 0. 0. 0. 1. 0. 0.]\n","                                [0. 0. 0. 0. 0. 1. 0.]\n","                                [0. 0. 1. 0. 0. 0. 0.]\n","                                [0. 0. 0. 0. 0. 0. 1.]]\n","\n","'The mouse ran down' = [[0. 0. 1. 0. 0. 0. 0. 0.]\n","                        [0. 0. 0. 1. 0. 0. 0. 0.]\n","                        [0. 0. 0. 0. 1. 0. 0. 0.]\n","                        [0. 0. 0. 0. 0. 0. 0. 1.]\n","                        [0. 1. 0. 0. 0. 0. 0. 0.]]\n","```"],"metadata":{"id":"CXASSJD9E3wk"}},{"cell_type":"markdown","source":["Impartim textele din dataset in tokeni."],"metadata":{"id":"oG8exJuIYZVh"}},{"cell_type":"code","source":["def transform_to_tokens(data):\n","\n","    reviews = []\n","    for review in data:\n","        review_tokenized = word_tokenize(review.lower())\n","        reviews.append(review_tokenized)\n","\n","    return reviews"],"metadata":{"id":"aKBCVNzETzUt","executionInfo":{"status":"ok","timestamp":1647392887230,"user_tz":-120,"elapsed":15,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["train_reviews = transform_to_tokens(train_df.review)\n","for r in train_reviews[:2]:\n","    print(r[:20])"],"metadata":{"id":"364y8q0KYGVy","executionInfo":{"status":"ok","timestamp":1647392900974,"user_tz":-120,"elapsed":13755,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"edb2e12b-414a-418a-bc31-10a5b5560beb"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["['it', 'is', 'interesting', 'to', 'see', 'what', 'people', 'think', 'of', 'this', 'movie', ',', 'since', 'it', 'is', ',', 'in', 'fact', ',', 'quite']\n","['did', 'the', 'first', 'travesty', 'actually', 'make', 'money', '?', 'this', 'is', 'another', 'sequel', '(', 'along', 'the', 'lines', 'of', 'another', 'stakeout', ')']\n"]}]},{"cell_type":"markdown","source":["Construim vocabularul de tokeni"],"metadata":{"id":"ufyvcVGLY2S8"}},{"cell_type":"code","source":["vocab = get_vocab(train_reviews)\n","\n","print('total words:', len(vocab))\n","print(list(vocab)[:100])"],"metadata":{"id":"TsV0rjqiY3Ta","executionInfo":{"status":"ok","timestamp":1647392901521,"user_tz":-120,"elapsed":285,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dfb2ec4a-c979-4aba-d20a-1461eecdf653"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["total words: 64266\n","['dr.tadokoro', 'jibes', 'ooooohhhh', 'advertised', 'willam', 'isolationist', 'redd', 'five-hundred-million', 'horsing', 'absurdest', 'gifts.', 'practitioner', 'tackles', 'turtlenecks', 'malta', '-screened', 'movie/theatre', 'drank', 'weaned', 'explicit', 'alluring.', 'renewal', 'cronenbergs', 'perplexity', 'sensibilities.', 'heck-of-a', 'shearer', 'received-', 'tastes', 'gurning', 'giardello', 'body-dissolving', 'dvd.', 'rewrote', 'bos', 'sharpen', 'picerni', 'context.', 'crushes', 'grand-mal', 'meet.so', 'ooooo', 'thriller.', 'barter', 'odder', 'raciest', 'amounted', 'no-talent', '3.99', 'elo', 'oppenheimer.', 'havegotten', 'trashes', 'hasidic', 'soup', 'inter', 'pappy', 'friel', 'missing.', 'reviewers', 'parole', 'c-', 'accentuated', 'doormen', 'pfieffer', 'riverbank.', 'piggy', 'brigite', 'flynn/gable', 'dilo', 'nationality', 'unfunniness', 'acting-directing', 'strong-willed', 'good/bad', 'almost-parallels', 'minnesota', 'fully-realized', 'me', 'muzaffer', 'stageplay', 'obliteration', 'disemboweled', 'guerilla-film-making', 'reining', 'other.', 'jin', 'beastly', 'ummmm', 'transatlantic', 'arthritic', 'erotically', 'love-spell', 'coherent.', 'stimulates', 'near-contemporary', 'step-father', 'videoasia', 'penned', 'ocron']\n"]}]},{"cell_type":"markdown","source":["Avem un vocabular foarte mare. Vom scoate din vocabular cuvintele cu o frecventa foarte mica. \n","\n","O alta abordare pentru micscorarea vocabularului este scoaterea cuvintelor foarte frecvente (stopwords). De asemenea putem face si alti pasi de preprocesare: putem face stemming, lematizare, putem scoate punctuatia, etc.)"],"metadata":{"id":"ROYnhY5aZk2F"}},{"cell_type":"code","source":["import operator\n","\n","def word_freq(data, min_aparitions):\n","    \n","    all_words = [words.lower() for sentences in data for words in sentences]\n","    sorted_vocab = sorted(dict(Counter(all_words)).items(), key=operator.itemgetter(1))\n","    final_vocab = [k for k,v in sorted_vocab if v > min_aparitions]\n","\n","    return final_vocab"],"metadata":{"id":"suBSGbXEZ21G","executionInfo":{"status":"ok","timestamp":1647392901523,"user_tz":-120,"elapsed":8,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["vocab = word_freq(train_reviews, min_aparitions = 10)\n","\n","print(vocab[:100])\n","print(len(vocab))"],"metadata":{"id":"mTvH9c6xah5I","executionInfo":{"status":"ok","timestamp":1647392902120,"user_tz":-120,"elapsed":604,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7c72c3f-b971-42f0-ee24-bfd6b040ad4c"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["['toll', 'denying', 'reported', 'shaft', 'histrionics', 'questioned', 'hurting', 'deliverance', 'backwoods', 'translate', 'dreadfully', 'bump', 'caper', 'sophomoric', 'hypnotic', 'washed', 'playful', 'stream', 'baddie', 'humiliating', 'necessity', 'incompetence', 'amidst', 'exposes', 'sirk', 'marc', 'interspersed', 'paste', 'grieving', 'tightly', 'masked', 'boil', 'marvin', 'cliffhanger', 'airing', 'video.', 'hilarious.', 'schneider', 'covert', 'holland', 'somber', 'salvage', 'sydow', 'towering', 'cannibalism', 'knives', 'shepard', 'remainder', 'two-dimensional', 'virtues', 'adapting', 'incidental', \"'it\", '..i', 'sites', 'observed', 'exploiting', 'ploy', 'czech', 'conflicted', 'stares', 'chiller', 'monument', 'raj', 'progressively', 'jox', 'tournament', 'stir', 'atop', 'shelter', 'backing', 'dives', 'dangers', 'unleashed', 'atomic', 'build-up', 'b-grade', 'garland', 'hamming', 'steele', 'orchestral', 'switched', 'opponent', 'cunning', 'chef', 'lottery', 'sumptuous', 'potent', 'spinning', 'honored', 'thankful', 'billie', 'piper', 'boards', 'hardest', 'brennan', 'distributors', 'backstory', 'sinks', 'dice']\n","9718\n"]}]},{"cell_type":"markdown","source":["Fiecarui token ii atribuim un indice."],"metadata":{"id":"EhIUcWG7Yeg-"}},{"cell_type":"code","source":["word_indices = dict((c, i + 2) for i, c in enumerate(vocab))\n","indices_word = dict((i + 2, c) for i, c in enumerate(vocab))\n","\n","indices_word[0] = 'UNK'\n","word_indices['UNK'] = 0\n","\n","indices_word[1] = 'PAD'\n","word_indices['PAD'] = 1"],"metadata":{"id":"ZH9CPMdib_VL","executionInfo":{"status":"ok","timestamp":1647392902121,"user_tz":-120,"elapsed":9,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["# print(indices_word)"],"metadata":{"id":"bdgbyjopXh8u","executionInfo":{"status":"ok","timestamp":1647392902429,"user_tz":-120,"elapsed":315,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":["Acum putem transforma propozitiile din datasetul nostru intr-o reprezentare vectoriala, in care vom avea pentru fiecare cuvant indicele corespunzator din vocabular."],"metadata":{"id":"csIrKV2Mc9Fh"}},{"cell_type":"code","source":["train_reviews_vectorized = vectorize_sentences(train_reviews, word_indices)"],"metadata":{"id":"-cPX7pE-XiCF","executionInfo":{"status":"ok","timestamp":1647392902885,"user_tz":-120,"elapsed":458,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["vectors_dim = [len(repr) for repr in train_reviews_vectorized]\n","vectors_dim[:5]"],"metadata":{"id":"vg4UHdQRdZzp","executionInfo":{"status":"ok","timestamp":1647392902887,"user_tz":-120,"elapsed":9,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf0381fc-6c27-45af-8139-5b83a889d687"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[423, 77, 186, 580, 288]"]},"metadata":{},"execution_count":98}]},{"cell_type":"markdown","source":["Din nou, pentru ca textele au un numar diferit de cuvinte, trebuie sa aducem vectorii la o reprezentare de aceeași dimensiune."],"metadata":{"id":"kbXLorrNd5Zt"}},{"cell_type":"code","source":["train_reviews_vectorized = pad(train_reviews_vectorized, max_length = 512)\n","train_reviews_vectorized"],"metadata":{"id":"g-KN_NNedhzo","executionInfo":{"status":"ok","timestamp":1647392903225,"user_tz":-120,"elapsed":344,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8918bc04-7e55-4b5c-8bdc-2dfbdb901dae"},"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[9707, 9712, 9486,  ...,    1,    1,    1],\n","        [9635, 9719, 9619,  ...,    1,    1,    1],\n","        [9704, 9697, 9712,  ...,    1,    1,    1],\n","        ...,\n","        [9705, 9301, 9719,  ...,    1,    1,    1],\n","        [9261, 9719,  251,  ...,    1,    1,    1],\n","        [9704, 9712, 9567,  ...,    1,    1,    1]])"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["train_reviews_vectorized.shape"],"metadata":{"id":"nzD9dy47d38U","executionInfo":{"status":"ok","timestamp":1647392903226,"user_tz":-120,"elapsed":12,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d606740b-733e-47c5-9ada-456d83caa732"},"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8000, 512])"]},"metadata":{},"execution_count":100}]},{"cell_type":"markdown","source":["# TASK\n","## Deadline: 31 martie ora 23:59.\n","\n","Formular pentru trimiterea temei: https://forms.gle/Bznaciv2MTy4kVL47\n","\n","Folosind intreg datasetul de mai sus (IMDb reviews) implementati urmatoarele cerinte:\n","1. Impartiti setul de date in 80% train, 10% validare si 10% test\n","2. Tokenizati textele si determinati vocabularul (in acest task vom lucra cu reprezentari la nivel de cuvant, NU la nivel de caracter); intrucat vocabularul poate fi foarte mare, incercati sa aplicati una dintre tehnicile mentionate in laborator (10K-20K de cuvinte ar fi o dimensiunea rezonabila a vocabularului)\n","3. Transformati textele in vectori de aceeasi dimensiune folosind indexul vocabularului (alegeti o dimensiune maxima de circa 500-1000 de tokens)\n","4. Implementati urmatoarea arhitectura:\n","    * un Embedding layer pentru vocabularul determinat, ce contine vectori de dimensiune 100\n","    * un layer dropout cu probabilitate 0.4\n","    * un layer convolutional 1D cu 100 canale de input si 128 de canale de output, dimensiunea kernelului de 3 si padding 1; asupra rezultatului aplicati un layer de [BatchNormalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) cu 128 features; aplicati apoi functia de activare ReLU, iar in cele din urma un strat de max-pooling 1D cu kernel size 2.\n","    * un layer convolutional 1D cu 128 canale de input si 128 de canale de output, dimensiunea kernelului de 5 si padding 2; asupra rezultatului aplicati un layer de BatchNormalization cu 128 features; aplicati apoi functia de activare ReLU, iar in cele din urma un strat de max-pooling 1D cu kernel size 2.\n","    * un layer convolutional 1D cu 128 canale de input si 128 de canale de output, dimensiunea kernelului de 5 si padding 2; asupra rezultatului aplicati un layer de BatchNormalization cu 128 features; aplicati apoi functia de activare ReLU, iar in cele din urma un strat de max-pooling 1D cu kernel size 2.\n","    * asupra rezultatului ultimului layer, aplicati average-pooling 1D obtinand pentru fiecare canal media tuturor valorilor din vectorul sau corespunzator\n","    * un layer feed-forward (linear) cu dimensiunea inputului 128, si 2 noduri pentru output (pentru clasificare in 0/1)\n","5. Antrenati arhitectura folosind cross-entropy ca functie de loss si un optimizer la alegere. La finalul fiecarei epoci evaluati modelul pe datele de validare si salvati weighturile celui mai bun model astfel determinat\n","6. Evaluati cel mai bun model obtinut pe datele de test.\n"],"metadata":{"id":"cP5P2WPwXLSy"}},{"cell_type":"code","source":[""],"metadata":{"id":"uSbL6Wb7bfNi","executionInfo":{"status":"ok","timestamp":1647392903226,"user_tz":-120,"elapsed":8,"user":{"displayName":"Bogdan Iordache","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-PZvTGY_WfhB97fLgLmkcd8CIjhKRDgsFQiip=s64","userId":"11937921055418047811"}}},"execution_count":100,"outputs":[]}]}