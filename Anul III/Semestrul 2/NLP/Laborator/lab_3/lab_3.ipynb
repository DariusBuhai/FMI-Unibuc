{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc86a84",
   "metadata": {
    "id": "4fc86a84"
   },
   "source": [
    "## Lab 3. Text classification using Bag-of-Words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ea606b",
   "metadata": {
    "id": "58ea606b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db25202",
   "metadata": {
    "id": "8db25202"
   },
   "source": [
    "### 1. Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75112f",
   "metadata": {
    "id": "ee75112f"
   },
   "source": [
    "Am vazut in laboratorul trecut cum putem folosi diverse tehnici pentru a reduce un text la o lista de cuvinte (tokens). Am vazut cum putem elimina cuvintele care au o incarcatura semantica redusa (stopwords) si cum putem normaliza tokenii, aducandu-i la o forma unica pentru inlfexiuni diferite ale acestora (lematizare, stemming).\n",
    "\n",
    "Pentru a antrena un model de Machine Learning avem nevoie sa mai facem cativa pasi. Aceste reprezentari determinate anterior (liste de tokens) trebuie traduse in reprezentari numerice vectoriale (fiecarui text ii vom asocia un vector, iar toti vectorii corespunzatori textelor vor avea aceeasi dimensiune)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3168a61",
   "metadata": {
    "id": "a3168a61"
   },
   "source": [
    "O astfel de metoda este reprezentarea textelor folosind tehnica Bag-of-Words. Aceasta metoda porneste de la un vocabular de cuvinte, un sir $[w_1, w_2, \\ldots, w_n]$, unde $w_i$ reprezinta un cuvant din vocabular. Vocabularul poate fi stabilit de la inceput sau determinat pe baza listelor preprocesate de tokeni (putem defini vocabularul ca cei mai frecventi $n$ tokens din aceste liste).\n",
    "\n",
    "Un text (lista de tokens) poate fi acum transformat intr-un vector de dimensiune $n$: $(a_1, \\ldots, a_n)$ unde $a_i=1$ daca cuvantul $w_i$ apare cel putin o data in text, respectiv $a_i=0$ altfel. Aceasta reprezentare o mai numim si Bag-of-Words binar.\n",
    "\n",
    "O altfel de reprezentare asemanatoare poate fi bazata pe frecvente, $a_i$ reprezinta numarul de aparitii ale cuvantului $w_i$ in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae68493f",
   "metadata": {
    "id": "ae68493f"
   },
   "outputs": [],
   "source": [
    "# exemplu texte (procesate ca liste de tokens)\n",
    "texts = [\n",
    "    [\"love\", \"fun\", \"fun\", \"play\", \"happy\", \"sad\"],\n",
    "    [\"love\", \"happy\", \"love\", \"love\", \"tears\"],\n",
    "    [\"sad\", \"tears\", \"tears\"],\n",
    "]\n",
    "\n",
    "# exemplu vocabular\n",
    "vocab = [\"love\", \"fun\", \"tears\", \"sad\", \"happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26baa2df",
   "metadata": {
    "id": "26baa2df"
   },
   "outputs": [],
   "source": [
    "# reprezentare BoW binar\n",
    "repr_bin = [\n",
    "    [1, 1, 0, 1, 1],\n",
    "    [1, 0, 1, 0, 1],\n",
    "    [0, 0, 1, 1, 0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ed4c0d",
   "metadata": {
    "id": "49ed4c0d"
   },
   "outputs": [],
   "source": [
    "# reprezentare BoW pe baza de frecvente\n",
    "repr_fr = [\n",
    "    [1, 2, 0, 1, 1],\n",
    "    [3, 0, 1, 0, 1],\n",
    "    [0, 0, 2, 1, 0],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb1a37",
   "metadata": {
    "id": "8ffb1a37"
   },
   "source": [
    "Aceasta logica poate fi implementata usor, dar aceasta poate fi regasita (impreuna cu alte detalii interesante) in clasa [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) din scikit-learn.\n",
    "\n",
    "Intr-un obiect de acest tip putem incorpora si logica de preprocesare+tokenizare a textelor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8985a53b",
   "metadata": {
    "id": "8985a53b"
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Love fun fun Play Happy sad\",\n",
    "    \"love happy Love love tears\",\n",
    "    \"sad Tears tears\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3371bc70",
   "metadata": {
    "id": "3371bc70"
   },
   "source": [
    "Implementam o preprocesare rudimentara a acestor texte, transformam toate majusculele in litere mici, iar pentru tokenizare dam split dupa spatiu. In cazul in care lucrati cu texte mai complexe, in acesti pasi includem ce am discutat in laboratorul anterior (eliminare de punctuatie, tokenizare, eliminare de stopwords, lematizare, stemming etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761b3404",
   "metadata": {
    "id": "761b3404",
    "outputId": "f1baf3fd-3817-4672-cf87-5be47d11f1a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'fun', 'fun', 'play', 'happy', 'sad']\n"
     ]
    }
   ],
   "source": [
    "def dummy_preprocess(text):\n",
    "    return text.lower()\n",
    "\n",
    "def dummy_tokenize(text):\n",
    "    return text.split(\" \")\n",
    "\n",
    "test_preprocess = dummy_preprocess(texts[0])\n",
    "test_tokens = dummy_tokenize(test_preprocess)\n",
    "print(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a62d4f",
   "metadata": {
    "id": "72a62d4f",
    "outputId": "e377416f-168b-41a5-874a-8edc98c71c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun', 'happy', 'love', 'sad', 'tears']\n",
      "(3, 5)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[1 1 1 1 0]\n",
      " [0 1 1 0 1]\n",
      " [0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(\n",
    "    preprocessor=dummy_preprocess,  # metoda de preprocesare a textelor\n",
    "    tokenizer=dummy_tokenize,       # metoda de tokenizare\n",
    "    token_pattern=None,             # nu avem nevoie de acest argument intrucat avem propria metoda de tokenizare\n",
    "    max_features=5,                 # dimensiunea vocabularului care va fi determinat\n",
    "    binary=True,                    # BoW binar\n",
    ")\n",
    "\n",
    "# metoda `fit` este folosita in acest caz pentru a determina vocabularul\n",
    "# (pastrand cei mai frecventi `max_features` tokens din textele procesate)\n",
    "cv.fit(texts)\n",
    "\n",
    "print(sorted(list(cv.vocabulary_.keys())))\n",
    "\n",
    "# calculeaza reprezentarile textelor (feature vectors)\n",
    "features = cv.transform(texts)\n",
    "print(features.shape)\n",
    "print(type(features))\n",
    "print(features.toarray())  # convertim la numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84022c67",
   "metadata": {
    "id": "84022c67",
    "outputId": "abbf274c-5828-42eb-9aa6-5699750e36b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun', 'happy', 'love', 'sad', 'tears']\n",
      "(3, 5)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[2 1 1 1 0]\n",
      " [0 1 3 0 1]\n",
      " [0 0 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(\n",
    "    preprocessor=dummy_preprocess, \n",
    "    tokenizer=dummy_tokenize,       \n",
    "    token_pattern=None,             \n",
    "    max_features=5,                 \n",
    "    binary=False,                   # BoW bazat pe frecvente\n",
    ")\n",
    "\n",
    "cv.fit(texts)\n",
    "\n",
    "print(sorted(list(cv.vocabulary_.keys())))\n",
    "\n",
    "# calculeaza reprezentarile textelor (feature vectors)\n",
    "features = cv.transform(texts)\n",
    "print(features.shape)\n",
    "print(type(features))\n",
    "print(features.toarray())  # convertim la numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e5de5",
   "metadata": {
    "id": "af3e5de5"
   },
   "source": [
    "O alternativa a acestor reprezentari este numararea n-gramelor.\n",
    "\n",
    "Sa luam spre exemplu fraza \"I am not happy\". Metoda de mai devreme ne reda reprezentarea acestei fraza ca o multime de cuvinte (indiferent de ordinea lor). Astfel, aceasta reprezentare indica prezenta cuvantului \"happy\", ceea ce ar face un model sa interpreteze textul intr-un cadru pozitiv. Dar vedem clar ca nu este aceasta situatia. Daca in loc de tokeni simpli (unigrame) am numara secvente de cate 2 tokeni consecutivi (bigrame), am putea identifica prezenta bigramei (\"not\", \"happy\") care intuim ca nu ar avea ce cauta intr-un text cu sentiment pozitiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe4c428",
   "metadata": {
    "id": "1fe4c428",
    "outputId": "f8baf33c-2bea-48f5-ac5a-3881572a9b4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun fun', 'fun play', 'happy love', 'happy sad', 'love fun']\n",
      "(3, 5)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[1 1 0 1 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(\n",
    "    preprocessor=dummy_preprocess, \n",
    "    tokenizer=dummy_tokenize,       \n",
    "    token_pattern=None,             \n",
    "    max_features=5,                 \n",
    "    ngram_range=(2, 2),                   # construim un vocabular de bigrame\n",
    ")\n",
    "\n",
    "cv.fit(texts)\n",
    "\n",
    "print(sorted(list(cv.vocabulary_.keys())))\n",
    "\n",
    "# calculeaza reprezentarile textelor (feature vectors)\n",
    "features = cv.transform(texts)\n",
    "print(features.shape)\n",
    "print(type(features))\n",
    "print(features.toarray())  # convertim la numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fd48c",
   "metadata": {
    "id": "d83fd48c"
   },
   "source": [
    "### 2. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e5179",
   "metadata": {
    "id": "134e5179"
   },
   "source": [
    "#### Standard Scaling\n",
    "\n",
    "Avand determinati feature vectorii se pune urmatoarea problema: stiind ca un feature reprezinta frecventa unui cuvant din vocabular in texte, iar pentru anumite cuvinte in mod natural aceasta frecventa este mai mare (Zipf's Law), faptul ca anumite feature-uri au valoare absoluta mai mare decat alta poate influenta diversi algoritmi de ML sa trateze acele feature-uri cu mai multa importanta (ceea ce de multe ori nu este corect).\n",
    "\n",
    "Prin Standard Scaling presupunem ca fiecare feature corespunde cate unei variabile aleatoare distribuita normal. Putem deci estima pentru fiecare astfel de variabila media si deviatia standard, apoi prin procesul de standardizare putem reduce valorile feature-ului corespunzator la o distributie normala de medie $0$ si varianta $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9791f91",
   "metadata": {
    "id": "e9791f91",
    "outputId": "a163e5e3-a5a2-4914-8ff2-e61aa266a609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media = [1.         0.         0.33333333]\n",
      "std = [0.81649658 0.81649658 1.24721913]\n",
      "[[ 0.         -1.22474487  1.33630621]\n",
      " [ 1.22474487  0.         -0.26726124]\n",
      " [-1.22474487  1.22474487 -1.06904497]]\n",
      "[[-2.44948974  1.22474487 -0.26726124]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[1, -1, 2], [2, 0, 0], [0, 1, -1]], dtype=np.float64)\n",
    "x_test = np.array([[-1, 1, 0]], dtype=np.float64)\n",
    " \n",
    "# clasa folosita pentru standardizare\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# calculam media si deviatia standard pentru feature vectorii de antrenare\n",
    "scaler.fit(x_train)\n",
    "\n",
    "print('media =', scaler.mean_)  \n",
    "print('std =', scaler.scale_) \n",
    "\n",
    "# scalam vectorii de train\n",
    "scaled_x_train = scaler.transform(x_train)\n",
    "print(scaled_x_train)  \n",
    "\n",
    "# scalam vectorii de test\n",
    "# (folosim media si std determinate din train, datele de test nu sunt folosite pentru a determina hiperparametrii)\n",
    "scaled_x_test = scaler.transform(x_test)\n",
    "print(scaled_x_test)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35243cb",
   "metadata": {
    "id": "b35243cb"
   },
   "source": [
    "#### Normalizare L1 si L2\n",
    "\n",
    "Acest mod de normalizare este mai simplu intrucat nu mai necesita determinarea unor parametrii. Fiecare feature vector este impartit prin norma sa (L1 sau L2), obtinand astfel ca toti vectorii corespunzatoari textelor sa aiba norma 1.\n",
    "\n",
    "$$x{\\_}scaled_1 = \\frac{X}{\\mid\\mid X \\mid\\mid_1}, \\mid\\mid X \\mid\\mid_1 = \\sum_{i=1}^{i=n}\\mid x_i \\mid $$\n",
    "$$x{\\_}scaled_2 = \\frac{X}{\\mid\\mid X \\mid\\mid_2}, \\mid\\mid X \\mid\\mid_2 = \\sqrt{\\sum_{i=1}^{i=n} x_i ^ 2 }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ad1e98",
   "metadata": {
    "id": "47ad1e98",
    "outputId": "cbc06736-4bc6-440d-e4d6-9df6966ef01b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25 -0.25  0.5 ]\n",
      " [ 1.    0.    0.  ]\n",
      " [ 0.    0.5  -0.5 ]]\n",
      "[[-0.5  0.5  0. ]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[1, -1, 2], [2, 0, 0], [0, 1, -1]], dtype=np.float64)\n",
    "x_test = np.array([[-1, 1, 0]], dtype=np.float64)\n",
    "\n",
    "# clasa folosita pentru normalizare\n",
    "scaler = preprocessing.Normalizer(norm='l1') \n",
    "# scaler = preprocessing.Normalizer(norm='l2')\n",
    "\n",
    "# `fit` aici nu face absolut nimic\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# scalam vectorii de train\n",
    "scaled_x_train = scaler.transform(x_train)\n",
    "print(scaled_x_train)  \n",
    "\n",
    "# scalam vectorii de test\n",
    "scaled_x_test = scaler.transform(x_test)\n",
    "print(scaled_x_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c1c37",
   "metadata": {
    "id": "641c1c37"
   },
   "source": [
    "### 3. Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc92232",
   "metadata": {
    "id": "cbc92232"
   },
   "source": [
    "O alta metoda de normalizare a feature-urilor pentru reprezentarea Bag-of-Words este **Tf-Idf**.\n",
    "\n",
    "**Term Frequency (TF)** numara pentru un token si un document de cate ori apare tokenul respectiv in document.\n",
    "\n",
    "O varianta de calcul pentru un token $t$ si un document $d$ ar fi: $\\textrm{tf}(t, d) = log(1 + \\textrm{frecv}(t, d))$.\n",
    "\n",
    "**Inverse Document Frequency (IDF)** iluestreaza cat de comun sau rar este un cuvant intr-un intreg corpus (multime de texte). Astfel, cu cat aceasta valoare se apropie de $0$ tokenul respectiv este mai comun.\n",
    "\n",
    "Pentru un token $t$, o multime de $N$ documente $D$, putem calcula IDF astfel: $\\textrm{idf}(t, D) = \\log(\\frac{N}{|\\{d \\in D: t \\textrm{ apare in } d\\}|})$.\n",
    "\n",
    "**TF-IDF** combina cele doua formule:\n",
    "$$\\textrm{tfidf}(t, d, D) = \\textrm{tf}(t, d) \\cdot \\textrm{idf}(t, D)$$.\n",
    "\n",
    "Mai multe informatii [aici](https://ro.wikipedia.org/wiki/Tf%E2%80%93idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53971e83",
   "metadata": {
    "id": "53971e83",
    "outputId": "f9e8d610-3e52-457b-8bcf-6b19c10c29e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun', 'happy', 'love', 'sad', 'tears']\n",
      "(3, 5)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[0.83513325 0.31757018 0.31757018 0.31757018 0.        ]\n",
      " [0.         0.30151134 0.90453403 0.         0.30151134]\n",
      " [0.         0.         0.         0.4472136  0.89442719]]\n"
     ]
    }
   ],
   "source": [
    "# exemplu TfidfVectorizer\n",
    "\n",
    "cv = TfidfVectorizer(\n",
    "    preprocessor=dummy_preprocess, \n",
    "    tokenizer=dummy_tokenize,       \n",
    "    token_pattern=None,             \n",
    "    max_features=5,\n",
    ")\n",
    "\n",
    "cv.fit(texts)\n",
    "\n",
    "print(sorted(list(cv.vocabulary_.keys())))\n",
    "\n",
    "# calculeaza reprezentarile textelor (feature vectors)\n",
    "features = cv.transform(texts)\n",
    "print(features.shape)\n",
    "print(type(features))\n",
    "print(features.toarray())  # convertim la numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b81a88",
   "metadata": {
    "id": "40b81a88"
   },
   "source": [
    "### 4. Clasificare folosind Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b788ead5",
   "metadata": {
    "id": "b788ead5",
    "outputId": "e7962242-96d8-4f0f-fcc9-a4089b6e3adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 10) (800,)\n",
      "(200, 10) (200,)\n"
     ]
    }
   ],
   "source": [
    "# generam o problema \"dummy\" de clasificare:\n",
    "# - 1000 de feature vectori de dimensiune 10 (din care doar 5 sunt relevanti pentru clasificare)\n",
    "# - fiecarui vector ii este asociat un label (0, 1 sau 2)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_classes=3, n_features=10, n_informative=5, n_redundant=5, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a620a91",
   "metadata": {
    "id": "8a620a91"
   },
   "source": [
    "Vom folosi pentru clasificare un decision tree (mai multe detalii [aici](https://en.wikipedia.org/wiki/Decision_tree_learning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b6a114",
   "metadata": {
    "id": "50b6a114"
   },
   "outputs": [],
   "source": [
    "# initializam un astfel de algoritm cu anumiti hiperparametri\n",
    "clf = DecisionTreeClassifier(max_depth=3, min_samples_split=5)\n",
    "\n",
    "# antrenam folosind datele de train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# folosim modelul pentru a prezice labelurile de test\n",
    "y_test_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f75d0",
   "metadata": {
    "id": "d47f75d0"
   },
   "source": [
    "### 5. Metrici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa802f",
   "metadata": {
    "id": "50aa802f"
   },
   "source": [
    "Avem mai multe metrici pe care le putem folosi pentru a determina performanta unui astfel de model. Pornim de la cazul simplu al unei probleme de clasificare binara (0/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d28a94",
   "metadata": {
    "id": "48d28a94"
   },
   "outputs": [],
   "source": [
    "y_true    = [0, 0, 0, 1, 1, 1, 1]\n",
    "y_predict = [0, 1, 0, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195e9eb",
   "metadata": {
    "id": "2195e9eb"
   },
   "source": [
    "Definim:\n",
    " * TP (true positive): numarul de labeluri 1 prezise corect\n",
    " * FP (false positive): numarul de labeluri 1 prezise incorect\n",
    " * TN (true negative): numarul de labeluri 0 prezise corect\n",
    " * FN (false negative): numarul de labeluri 0 prezise incorect\n",
    " \n",
    "Acuratetea se calculeaza dupa formula:\n",
    "$$\\frac{TP+TN}{TP+FP+TN+FN}$$\n",
    "\n",
    "Cu alte cuvinte cate labeluri au fost prezise corect din totalul de predictii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b101b4a6",
   "metadata": {
    "id": "b101b4a6",
    "outputId": "e970be4e-1343-4b22-81bf-a5c9763603bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_true, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746be29",
   "metadata": {
    "id": "6746be29"
   },
   "source": [
    "Acuratetea nu este mereu metrica preferabila. In cazul unei probleme dezechilibrate (imbalanced) in care $99\\%$ din obiecte au labelul $0$ si doar $1\\%$ au labelul $1$, un clasificator care prezice doar labelul $0$ pentru toate exemplele ar avea acuratete $99\\%$! Daca problema ar fi fost detectare de spam, sau detectarea simptomelor asociate unui anumit tip de cancer, un astfel de model nu ar fi considerat unul performant.\n",
    "\n",
    "Introducem astfel alte cateva metrici:\n",
    " * P (precision): $\\frac{TP}{TP+FP}$ (dintre toate predictiile 1, cate sunt corecte?)\n",
    " * R (recall): $\\frac{TP}{TP+FN}$ (dintre toate obiectele din clasa 1, cate am reusit sa prezicem corect?)\n",
    " * F1: $\\frac{2PR}{P+R}$ (media armonica intre precision si recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fa6fa30",
   "metadata": {
    "id": "2fa6fa30",
    "outputId": "4cd51f21-34dc-4409-efbe-8841fb3c1ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6666666666666666\n",
      "Recall: 0.5\n",
      "F1: 0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\", metrics.precision_score(y_true, y_predict))\n",
    "print(\"Recall:\", metrics.recall_score(y_true, y_predict))\n",
    "print(\"F1:\", metrics.f1_score(y_true, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62475112",
   "metadata": {
    "id": "62475112"
   },
   "source": [
    "In cazul problemelor de clasificare de tip multi-class (mai mult de 2 clase). Acuratetea pastreaza acelasi sens de \"cate predictii sunt corecte din totalul predictiilor\".\n",
    "\n",
    "Precision, Recall si F1 se calculeaza intr-o maniera one-vs-rest. Astfel fixand o anumita clasa, transformam labelurile in $1$ daca labelul original corespunde clasei fixate si $0$ altfel. Putem acum calcula aceste metrici in cazul binar. Rezultatele obtinute pentru fiecare astfel de fixare sunt acumulate si rezultatul final este media acestora (calculata ca medie aritmetica - macro, sau ca medie ponderata - weighted in care ponderile sunt date de numarul de exemple din clasa respectiva)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a83260f9",
   "metadata": {
    "id": "a83260f9",
    "outputId": "bf4ad367-4025-4511-8e64-4baca9d14cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "F1 (macro): 0.6935607271177741\n",
      "F1 (weighted): 0.6932996310177518\n"
     ]
    }
   ],
   "source": [
    "# calculam acuratete si F1 pentru clasificarea de mai devreme\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_test_predict))\n",
    "print(\"F1 (macro):\", metrics.f1_score(y_test, y_test_predict, average=\"macro\"))\n",
    "print(\"F1 (weighted):\", metrics.f1_score(y_test, y_test_predict, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "707cad42",
   "metadata": {
    "id": "707cad42",
    "outputId": "9b63015e-01df-4dba-ee4a-311280633d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76        68\n",
      "           1       0.67      0.86      0.75        65\n",
      "           2       0.65      0.51      0.57        67\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.70      0.70      0.69       200\n",
      "weighted avg       0.70      0.70      0.69       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b30fd0",
   "metadata": {
    "id": "67b30fd0"
   },
   "source": [
    "O vizualizare utila este si matricea de confuzie in care numaram $A[i][j]$ cate obiecte din clasa $i$ au fost prezise ca facand parte din clasa $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d922431f",
   "metadata": {
    "id": "d922431f",
    "outputId": "4defa47b-0626-458f-dbf7-c92f11e49d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  7 11]\n",
      " [ 2 56  7]\n",
      " [12 21 34]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_test_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9760e755",
   "metadata": {
    "id": "9760e755",
    "outputId": "cc63d7cf-6759-4220-ad59-6ec9ad200f81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVe0lEQVR4nO3df5yVc97H8dfnTDOqKaUfkqkt9y3bYsmykXYLtcnvllhZhBjcuCMWt9a96152s9Zv+6NBapekkF97C0uhG4VKvyMJU1Gq2X5spZnzuf+YI4Oac0bne64z17yfHtejc13nnOt8zKPHu+98vt/rOubuiIhIOImoCxARiTsFrYhIYApaEZHAFLQiIoEpaEVEAmsU+gM2vTJayxoC2//ku6IuoUHo2LhV1CXE3pTyf9jOnmPrZ0syzpzCNv+205+XieBBKyKSU8mqqCv4BgWtiMSLJ6Ou4BsUtCISL0kFrYhIUK4RrYhIYFWVUVfwDQpaEYkXTYaJiASm1oGISGCaDBMRCUuTYSIioWlEKyISWNXWqCv4BgWtiMSLWgciIoGpdSAiEphGtCIigWlEKyISlic1GSYiEpZGtCIigalHKyISmG4qIyISmEa0IiKBZbFHa2ZLgfVAFVDp7oeYWSvgEaAzsBQ4zd3X1nYefd24iMRLVWXmW2aOdPdu7n5Iav9a4EV37wK8mNqvlYJWROIlmcx8+3ZOAsakHo8BBqR7g4JWRGLFvSrjLZPTAc+b2dtmVpo61s7dV6QefwK0S3cS9WhFJF7qMFJNhWdpjUNl7l5WY/9H7r7MzHYHXjCzhTXf7+5uZp7ucxS0IhIvdVh1kArVslqeX5b6c6WZTQS6A5+aWXt3X2Fm7YGV6T5HrQMRiZcs9WjNrNjMmn/xGOgHzAWeAganXjYYeDJdSRrRiki8ZO/rxtsBE80MqrNyrLtPMrM3gfFmNgT4EDgt3YkUtCISL1m6YMHdlwAHbuf4aqBPXc6loBWReNFNZUREAlPQ5p9jrv0TxY2LSJjRqCDB2F+eyz83buLqkU+wfPU/2bN1C265cAC7FjeJutRY2GvvTtx174ht+x07l3DHiL8weuTYCKuq/67+w1X06HsoFZ9VcG7fCwDofVwvzhl2Np26fIeLj7+URbPfjbjKHNG9DvLTvVeewW7Nm27bH/Xs6xz6vc6cd0wPRj37OqOefYPLBx4ZYYXx8cHiDznhyEEAJBIJXpszief/Pjniquq/SROeY+LoJ7jujmu2Hftg0VL++4Jfc+XNV0RYWQSyNxmWNVretR1TZr3HCT2+D8AJPb7P5FkNZCSQY4f36s5HS8tZXr4i/YulVrOnzWF9xfqvHPto8Ud8vKQ8oooiFP4S3Dpr8CNaAy6+YxyGcUrvbgzsdRCr122kbctmALRpUczqdRujLTKmjv/p0Tz9+HNRlyFxUx9bB2bWleqbKJSkDi0DnnL3BSELy5UHrjmLdrs1Z826jVx0+zj22qP1V543M1Lr6CSLCgsb0ad/L2658e6oS5G4ycPJsFpbB2Z2DTCO6oHf9NRmwMNmtsNbg5lZqZm9ZWZv3f/UlCyWm33tdmsOQKtdiznyoH2Y+8EKWu9azKqKDQCsqthAqxr9W8mO3n17Mm/2QlavWhN1KRI39bB1MATYz92/8rWSZnYbMA8Ysb031bx+eNMro9PecCEqm7Z8TtKd4sa7sGnL57w+/wMuPL4nvQ/swtOvz+G8Y3rw9OtzOKJbl6hLjZ0TTu6vtoGE4fkXOemCNgnsSfVlZjW1Tz1Xr61et5Fhf3ocgMqqJMccui899/939uvcnqtHPsHEqe+wZ+sW/P7CAdEWGjNNmjamZ+9DGT7spqhLiY3r77mObj0OpEWrFkx482EeuHUM6yrWM/Q3l9KiVQt+N+YmFs97n6vPTHuP6vqvMv9WHZjXkv5m1h+4B3gP+Dh1+DvA3sCl7j4p3Qfk84g2LvY/+a6oS2gQOjZuFXUJsTel/B87PSGy6cHhGWdOkzNvyskETK0j2tQNFPah+tZgNSfD3vQM75orIpJTeTgZlnbVgbsngTdyUIuIyM6rhz1aEZH6pT6OaEVE6hUFrYhIWF6Vf9NHCloRiReNaEVEAquP9zoQEalXklp1ICISlloHIiKBaTJMRCQwjWhFRAJTj1ZEJDCtOhARCUwjWhGRsFw9WhGRwLTqQEQkMLUOREQCU+tARCQwjWhFRALT8i4RkcDycESbiLoAEZFs8sqqjLdMmFmBmc00s2dS+3uZ2TQzW2xmj5hZUbpzKGhFJF6SnvmWmaHAghr7NwO3u/vewFpgSLoTKGhFJF48mfmWhpl1AI4D7kvtG3AU8GjqJWOAAenOo6AVkXipw4jWzErN7K0aW+nXznYHcDXwRSq3BircvTK1Xw6UpCtJk2EiEiteh8kwdy8Dyrb3nJkdD6x097fN7IidqUlBKyLxkuEkVwZ6Aiea2bFAY2BX4E6gpZk1So1qOwDL0p1IrQMRiZcsTYa5+3+5ewd37wycDrzk7j8HJgMDUy8bDDyZriQFrYjES/ZXHXzdNcAwM1tMdc/2/nRvUOtARGLFPfsXLLj7FGBK6vESoHtd3q+gFZF4ycMrwxS0IhIvDTFom/cdHvojGrxNy1+NuoQGoWvXgelfJJHzSt1URkQkrPzLWQWtiMRLXS5YyBUFrYjEi4JWRCQwtQ5ERMJS60BEJDCvVNCKiISl1oGISFh5+N2MCloRiRkFrYhIWBrRiogEtu1LZvKIglZEYkUjWhGRwBS0IiKhuUVdwTcoaEUkVjSiFREJzJMa0YqIBJWsUtCKiASl1oGISGBqHYiIBBbg28Z3moJWRGJFI1oRkcA0GSYiEphGtCIigbmuDBMRCUvLu0REAktqRCsiEpZaByIigeXjqoNE1AWIiGSTJy3jrTZm1tjMppvZO2Y2z8xuSB3fy8ymmdliM3vEzIrS1aSgFZFYSbplvKWxBTjK3Q8EugH9zeww4GbgdnffG1gLDEl3IgWtiMSKu2W81X4ed3ffkNotTG0OHAU8mjo+BhiQrib1aFM6dNiT0aPuZPd2bXB37rvvIe6+5/6oy4qNfqcMprhpUxKJBAUFBYwfdRcAD014knGPP0MikaDX4d258pK0gwNJY6+9O3HXvSO27XfsXMIdI/7C6JFjI6wqd+pyrwMzKwVKaxwqc/eyGs8XAG8DewN/BN4HKty3fQVkOVCS7nMUtCmVlZX84uobmDlrLs2aFTN92iT+8eIrLFjwXtSlxcaou0ewW8sW2/anv/0Ok6e+wWNj/khRURGr11ZEV1yMfLD4Q044chAAiUSC1+ZM4vm/T464qtypy/KuVKiW1fJ8FdDNzFoCE4Gu36YmtQ5SPvlkJTNnzQVgw4aNLFz4HiV77hFxVfH2yBN/Z8iZp1FUVD2X0Hq3ltEWFEOH9+rOR0vLWV6+IupSciaZtIy3TLl7BTAZ6AG0NLMvBqkdgGXp3q+g3Y5OnTrQ7cD9mTZ9ZtSlxIaZUXrFcE477zImPPm/ACz9aBlvvzOXQRdczjmX/II5CxZFXGX8HP/To3n68eeiLiOnsjUZZmZtUyNZzKwJ8BNgAdWBOzD1ssHAk+lq+tatAzM7190f2MFz2/oeVtCCRKL4235MzhUXN2X8I/cy7KpfsX79hvRvkIz89c9/oF3bNqxeW8EFl1/HXp06UlVVxbp16xlbdjtzF7zLVdf/jkkTHsAs/9ZB1keFhY3o078Xt9x4d9Sl5FQWL1hoD4xJ9WkTwHh3f8bM5gPjzOxGYCaQdjJnZ3q0NwDbDdqafY9GRSV5eBve7WvUqBETHrmXhx+eyBNPPBt1ObHSrm0boLo90KfX4cyZv4h2u7ehb++emBnf3/e7mBlrK/5JK7UQsqJ3357Mm72Q1avWRF1KTmXrElx3nw0ctJ3jS4DudTlXrUFrZrN39BTQri4fVB/cW3YrCxYu5o47d9gbl2/hX5s248kkxcVN+demzbw2fQYXn3sGTZs0YfqMd+h+8IEs/aicrZWVX5ksk51zwsn9G1zbAKrXX+WbdCPadsDRVC/KrcmA14JUFJGeh/+Qs84cyOw583nrzecBuP76ETw76aWIK6v/Vq9Zy9DrfgNAVWUVx/Y7gh8ddghbt27ll7+9nQFnXkRhYSN++8sr1TbIkiZNG9Oz96EMH3ZT1KXkXFUy/6aezGtZdGZm9wMPuPvU7Tw31t3PSPcB9al1UF9tWv5q1CU0CF27Dkz/Itkp7382Y6f/pX11j4EZZ86PP3k0J/+y1zqidfcdrh7PJGRFRHLNyb/finTBgojESjIPf4dW0IpIrCQ1ohURCUutAxGRwKoUtCIiYeXhdzMqaEUkXhS0IiKBqUcrIhJYHe5+mDMKWhGJFS3vEhEJrCrqArZDQSsisZLMwxsTKWhFJFby8ApcBa2IxIuWd4mIBKZVByIigekSXBGRwDSiFREJTD1aEZHAtOpARCQwtQ5ERAJT60BEJLAqjWhFRMLSiFZEJDAFrYhIYFp1ICISmFYdiIgEptaBiEhg+Xjj70TUBYiIZFPSMt9qY2YdzWyymc03s3lmNjR1vJWZvWBm76X+3C1dTQpaEYmVZB22NCqBK919X+Aw4BIz2xe4FnjR3bsAL6b2a6WgFZFY8TpstZ7HfYW7z0g9Xg8sAEqAk4AxqZeNAQakqyl4j7ZPuwNCf0SDd9cP/jvqEhqEqV1bRF2CZCBZhwVeZlYKlNY4VObuZdt5XWfgIGAa0M7dV6Se+gRol+5zNBkmIrFSl8mwVKh+I1hrMrNmwGPA5e6+zmp8+aO7u5mlTXa1DkQkVrLYo8XMCqkO2Yfc/fHU4U/NrH3q+fbAynTnUdCKSKxkcdWBAfcDC9z9thpPPQUMTj0eDDyZria1DkQkVurSo02jJ3AWMMfMZqWOXQeMAMab2RDgQ+C0dCdS0IpIrGQrZt19Kuzwmx771OVcCloRiRVdgisiElhVHt6/S0ErIrGiEa2ISGBZnAzLGgWtiMRK/sWsglZEYkatAxGRwDQZJiISmHq0IiKB5V/MKmhFJGY0ohURCUyTYSIigblGtCIiYWnVgYhIYGodiIgElnSNaEVEgsq/mFXQikjMaHmXiEhgWnUgIhJYpYJWRCQsjWhFRALT8i4RkcBcy7tERMLSqgMRkcB0Ca6ISGAa0YqIBKYebR4a9ocrOLRPdypWV3Bh34sBOH/4EA7reyhbt1ay4sMV3HrlbWxctzHiSuun5u1b0f/2iyhu2wJ3Z/bYycwc9Rz7HNedHlecTOu99+ShE3/Fp7M/iLrU+q2okNb33IkVFUFBAZsnv8yGUaO3Pb3r0MtoctwxfNrv2OhqzJF8XHWQiLqAqD0/4QWGn/XLrxyb8epMSvtexMX9/oNlS5Zx+iU/i6i6+i9ZleTlG8cyus81jD3p13Q7uy+tuuzJZ4vKear0TsqnLYq6xHj4fCtrhg7js3PO57NzzmeXw7pTuN/3ACj87j5Y82YRF5g7Xof/cqXBB+3caXNZX7H+K8dmvDKDZFX1v4sLZi6kTfs2UZQWCxtXVrBy7lIAtm7czJrFy2m+RyvWLF7O2iUroi0uZnzT5uoHjRphBQXVd1dJJGh+yUWs//PISGvLpSSe8ZYrDb51kM7Rp/Xj5adfjrqMWNi1Qxt2368TK2a+H3Up8ZRI0Ob+kRSUlPCviU+wdf4Cmp56ClumvkZy9Zqoq8uZKs+/5kHaEa2ZdTWzPmbW7GvH+4crKz8Muux0qqqqeGni5KhLqfcKm+7CiSOHMvmGB/l8w6aoy4mnZJLPzr2AlSefSuH3ulJ04AE0ObI3Gx97POrKcqretQ7M7D+BJ4HLgLlmdlKNp39by/tKzewtM3urfMPH2ak0x35yal+69+nOzZf9PupS6r1EowJOHDmUBRNfY/Gkt6IuJ/Z8w0Y+nzGLoh90o6CkhLbjHqLthIexxrvQdtyDUZcXXNI94y0dMxtlZivNbG6NY63M7AUzey/1527pzpNuRHsBcLC7DwCOAK43s6FffN6O3uTuZe5+iLsf0qFZx7T/M/nmkCMO5tSLTuXX593Als1boi6n3ut3y/msXryct+97NupSYivRsgXWrLh6p6iIXX54MFsXvcvKk05h1amDWHXqIHzzFladfma0heaA12HLwGjg67+9Xwu86O5dgBdT+7VK16NNuPsGAHdfamZHAI+aWSdqCdr65Np7ruGAww6gRatdeXD63/jbrX/j9Et/RmFRIb8bexMAC2cs5K7r7om40vqp5If7sN8pP2bVgo8469nqn+fU34+noKiQo/7nbJq0as5PH7iKVfM/5LGz9NvDt5Vo3ZqWw6+FRAISCTa/NIUtr70RdVmRyOYkl7u/Ymadv3b4JKoHngBjgCnANbWdx2pb3GtmLwHD3H1WjWONgFHAz929IF2hR3c8Jv9WD8dMP2sddQkNwhnfWRZ1CbHXfurknR7A9Sg5MuPMeX1Z+s9LBe0z7r5/ar/C3VumHhuw9ov9HUnXOjgb+KTmAXevdPezgV7pChQRybUqT2a81ZxPSm2ldfksrx6ppg32WlsH7l5ey3P/V5eCRERyoS6rCdy9DCir40d8ambt3X2FmbUHVqZ7Q4O/YEFE4sXdM96+paeAwanHg6lemVUrXbAgIrGSzckwM3uY6omvNmZWDvwKGAGMN7MhwIfAaenOo6AVkVjJ5t273H3QDp7qU5fzKGhFJFaq8vD+XQpaEYmVTK74yjUFrYjEir5uXEQkMI1oRUQC04hWRCQwjWhFRALLxxt/K2hFJFbUOhARCcw1ohURCSuXX7qYKQWtiMRKNi/BzRYFrYjEika0IiKBVSXVoxURCUqrDkREAlOPVkQkMPVoRUQC04hWRCQwTYaJiASm1oGISGBqHYiIBKbbJIqIBKZ1tCIigWlEKyISWFK3SRQRCUuTYSIigSloRUQCy7+YBcvH9I+amZW6e1nUdcSZfsbh6WecPxJRF5CnSqMuoAHQzzg8/YzzhIJWRCQwBa2ISGAK2u1TXys8/YzD0884T2gyTEQkMI1oRUQCU9CKiASmoK3BzPqb2SIzW2xm10ZdTxyZ2SgzW2lmc6OuJa7MrKOZTTaz+WY2z8yGRl1TQ6cebYqZFQDvAj8ByoE3gUHuPj/SwmLGzHoBG4C/uvv+UdcTR2bWHmjv7jPMrDnwNjBAf5ejoxHtl7oDi919ibt/DowDToq4pthx91eANVHXEWfuvsLdZ6QerwcWACXRVtWwKWi/VAJ8XGO/HP3llHrOzDoDBwHTIi6lQVPQisSUmTUDHgMud/d1UdfTkClov7QM6Fhjv0PqmEi9Y2aFVIfsQ+7+eNT1NHQK2i+9CXQxs73MrAg4HXgq4ppE6szMDLgfWODut0Vdjyhot3H3SuBS4DmqJw/Gu/u8aKuKHzN7GHgd+K6ZlZvZkKhriqGewFnAUWY2K7UdG3VRDZmWd4mIBKYRrYhIYApaEZHAFLQiIoEpaEVEAlPQiogEpqAVEQlMQSsiEtj/Ayex8XDvhR6WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9b02d",
   "metadata": {
    "id": "78e9b02d"
   },
   "source": [
    "### 6. Importanta feature-urilor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893d1dd",
   "metadata": {
    "id": "d893d1dd"
   },
   "source": [
    "Intuitiv anumite feature-uri sunt mai importante decat altele cand vine vorba de clasificare. Prezenta cuvantului \"happy\" sau \"sad\" ne poate oferi informatii despre sentimentul unui text, pe cand cuvantul \"car\", nu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0b88cc5",
   "metadata": {
    "id": "e0b88cc5",
    "outputId": "b4e8d50d-a950-4ffd-93b2-7dab27f9181a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.11837956006934854\n",
      "Feature: 1, Score: 0.0\n",
      "Feature: 2, Score: 0.4172424563910119\n",
      "Feature: 3, Score: 0.039030730202152863\n",
      "Feature: 4, Score: 0.0\n",
      "Feature: 5, Score: 0.21084131505634365\n",
      "Feature: 6, Score: 0.0\n",
      "Feature: 7, Score: 0.04661388817258808\n",
      "Feature: 8, Score: 0.06021961536405184\n",
      "Feature: 9, Score: 0.10767243474450318\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pentru decision tree avem urmatoare metoda pentru a extrage aceasta importanta\n",
    "importance = clf.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "    print(f\"Feature: {i}, Score: {v}\")\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056deb9",
   "metadata": {
    "id": "6056deb9"
   },
   "source": [
    "Pentru alte modele exista diverse alte moduri de a extrage importanta feature-urilor (ex. logistic regression, SVM linear, Random Forest etc.), insa pentru altele este mult mai complicat sau chiar imposibil (ex. SVM cu kernel rbf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975369b0",
   "metadata": {
    "id": "975369b0"
   },
   "source": [
    "# TASK:\n",
    "\n",
    "### Deadline: 17 martie ora 23:59.\n",
    "### Formular pentru trimiterea temei: https://forms.gle/isPikzbiBdNm7AhA6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb71b7",
   "metadata": {
    "id": "edcb71b7"
   },
   "source": [
    "Vom folosi urmatorul dataset: https://www.kaggle.com/rmisra/news-category-dataset (headline-uri de stiri etichetate conform unei liste de categorii).\n",
    "\n",
    "1. (optional) Intrucat setul de date contine multe categorii, puteti pastra exemplele din 4-5 clase (selectate de catre voi) si sa rezolvati problema de clasificare doar pentru aceste exemple\n",
    "2. Incercati mai multe metode de preprocesare si tokenizare a textelor pentru a obtine reprezentari de tip Bag-of-Words (stergeti/nu stergeti stop words, lematizati sau aplicati stemming, pastrati sau eliminati punctuatia, normalizati folosind standardizare, L1, L2 sau Tf-Idf). Implementati **3** astfel de combinatii.\n",
    "3. Impartiti setul de date in 80% train, 20% test, iar pentru fiecare metoda de preprocesare antrenati un model ales de voi (diferit de Decision Tree) pe datele de train\n",
    "4. Evaluati modelul pe datele de test, determinand acuratete, precizie, recall, f1, si stabiliti care metoda de procesare a textelor a adus rezultate mai bune.\n",
    "5. Determinati pentru acest caz care au fost top 10 cele mai importante feature-uri (cuvinte).\n",
    "6. Folosind aceasta metoda de procesare a textelor, antrenati alte doua modele diferite la alegere si comparati performanta cu modelul original.\n",
    "7. Pentru cel mai bun model afisati metricile la nivel de clasa (classification report) si matricea de confuzie."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lab-nlp-an3",
   "language": "python",
   "name": "lab-nlp-an3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
