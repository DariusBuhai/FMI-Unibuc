{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2092081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from os import path\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D,Conv3D, MaxPooling2D, BatchNormalization, MaxPool2D,GlobalAveragePooling2D, MaxPool3D\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dcf0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    TUMOR_TYPES = ('native', 'arterial', 'venous')\n",
    "\n",
    "    @staticmethod\n",
    "    def load(input_file='train'):\n",
    "        images_arr, images_mat, labels = [], [], []\n",
    "        with open(f\"data/{input_file}.txt\", \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                line_data = line.replace(\"\\n\", \"\").split(\",\")\n",
    "                line = f.readline()\n",
    "                image_path = f\"data/{input_file}/{line_data[0]}\"\n",
    "                if not path.exists(image_path):\n",
    "                    continue\n",
    "\n",
    "                img_arr = imageio.imread(image_path)\n",
    "                img_arr = np.asarray(img_arr).reshape(-1)\n",
    "\n",
    "                img_mat = image.load_img(image_path, target_size=(50, 50, 1), color_mode='grayscale')\n",
    "                img_mat = image.img_to_array(img_mat)\n",
    "                img_mat = img_mat / 255\n",
    "\n",
    "                images_arr.append(img_arr)\n",
    "                images_mat.append(img_mat)\n",
    "\n",
    "                if len(line_data) > 1:\n",
    "                    labels.append(int(line_data[1]))\n",
    "        return images_mat, images_arr, labels\n",
    "\n",
    "    @staticmethod\n",
    "    def dump(predicted_labels, input_file=\"test\", output_file=\"test\"):\n",
    "        output = []\n",
    "        i = 0\n",
    "        with open(f\"data/{input_file}.txt\", \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                line_data = line.replace(\"\\n\", \"\").split(\",\")\n",
    "                line = f.readline()\n",
    "                output.append(f\"{line_data[0]},{predicted_labels[i]}\")\n",
    "                i += 1\n",
    "        with open(f\"data/submission_{output_file}.txt\", \"w\") as o:\n",
    "            o.write(\"id,label\\n\")\n",
    "            o.write(\"\\n\".join(output))\n",
    "\n",
    "    @staticmethod\n",
    "    def print_data(images, labels, r):\n",
    "        for i in range(r[0], r[1]):\n",
    "            image = np.reshape(images[i], (50, 50))\n",
    "            print(\"Tumor type:\", Data.TUMOR_TYPES[labels[i]])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff888f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_mat, test_images_arr, _ = Data.load(\"test\")\n",
    "train_images_mat, train_images_arr, train_labels = Data.load(\"train\")\n",
    "validation_images_mat, validation_images_arr, validation_labels = Data.load(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aab2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score: 0.74\n",
    "class CnnClassifier:\n",
    "    \n",
    "    BEST_MODEL = 'best_model.h5'\n",
    "    \n",
    "    def __init__(self, dropout = .4):\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        self.model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(50, 50, 1)))\n",
    "        print(self.model.output_shape)\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Conv2D(32, kernel_size=5, padding='same', strides=2, activation='relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(dropout))\n",
    "\n",
    "        self.model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Conv2D(64, kernel_size=5, padding='same', strides=2, activation='relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(dropout))\n",
    "        \n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(128, activation='relu'))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(dropout))\n",
    "        self.model.add(Dense(10, activation='softmax'))\n",
    "        \n",
    "        self.model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        \n",
    "        self.datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.10, width_shift_range=0.1, height_shift_range=0.1)\n",
    "        self.model_checkpoint = ModelCheckpoint(f'data/{self.BEST_MODEL}', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "        \n",
    "    def load_best(self):\n",
    "        if path.isfile(f'data/{self.BEST_MODEL}'):\n",
    "            self.model = load_model(f'data/{self.BEST_MODEL}')\n",
    "    \n",
    "    def train(self, train_images, train_labels, validation_images, validation_labels, epochs=5):\n",
    "        self.annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\n",
    "        self.model.fit(self.datagen.flow(train_images, train_labels, batch_size=64), epochs=epochs,\n",
    "                       steps_per_epoch=train_images.shape[0] // 64, callbacks=[self.annealer, self.model_checkpoint],\n",
    "                       validation_data=(validation_images, validation_labels))\n",
    "\n",
    "    def classify_images(self, test_images):\n",
    "        return self.model.predict_classes(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76a76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(ground_truth_labels, predicted_labels):\n",
    "    return np.mean(ground_truth_labels == predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "551ba675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(cnn_classifier, validation_images, validation_labels):\n",
    "    cnn_classifier.load_best()\n",
    "    predicted_labels = cnn_classifier.classify_images(validation_images)\n",
    "    acc = accuracy_score(validation_labels, predicted_labels)\n",
    "    print(f\"\\nAccuracy: {acc * 100}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a56e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confunsion_matrix(predicted_labels, ground_truth_labels):\n",
    "    num_labels = ground_truth_labels.max() + 1\n",
    "    conf_mat = np.zeros((num_labels, num_labels))\n",
    "    \n",
    "    for i in range(len(predicted_labels)):\n",
    "        conf_mat[ground_truth_labels[i], predicted_labels[i]] += 1\n",
    "    return  conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ef99aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_c = np.array(train_labels)\n",
    "train_images_c = np.array(train_images_mat)\n",
    "\n",
    "validation_labels_c = np.array(validation_labels)\n",
    "validation_images_c = np.array(validation_images_mat)\n",
    "\n",
    "test_images_c = np.array(test_images_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa54df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 48, 48, 32)\n"
     ]
    }
   ],
   "source": [
    "cnn_classifier = CnnClassifier(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6136a506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NumpyArrayIterator' object has no attribute 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-09f91d9d0101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcnn_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_images_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_labels_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-6aa98137347e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_images, train_labels, validation_images, validation_labels, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannealer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         self.model.fit(self.datagen.flow(train_images, train_labels, batch_size=64), epochs=epochs,\n\u001b[1;32m     48\u001b[0m                        \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannealer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NumpyArrayIterator' object has no attribute 'input_shape'"
     ]
    }
   ],
   "source": [
    "# Best: 0.76\n",
    "for i in range(5):\n",
    "    cnn_classifier.train(train_images_k, train_labels_k, validation_images_k, validation_labels_k, epochs=(10))\n",
    "    predicted_labels = cnn_classifier.classify_images(validation_images_k)\n",
    "    acc = accuracy_score(validation_labels_k, predicted_labels)\n",
    "    print(f\"\\nAccuracy: {acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13d4707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 81.6%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.816"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(cnn_classifier, validation_images_c, validation_labels_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "433e7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_classifier.load_best()\n",
    "predicted_labels = cnn_classifier.classify_images(validation_images_c)\n",
    "conf_mat = confunsion_matrix(predicted_labels, validation_labels_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801827d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81366b5670>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(conf_mat, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33054622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1453.   27.   20.]\n",
      " [ 192.  986.  322.]\n",
      " [ 184.   83. 1233.]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd95b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = cnn_classifier.classify_images(test_images_k)\n",
    "Data.dump(predicted_labels, \"test\", \"cnn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
